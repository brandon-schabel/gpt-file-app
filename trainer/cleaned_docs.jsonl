{"messages": [{"role": "user", "content": "Provide the content of docs/api/binary-data.md"}, {"role": "assistant", "content": "This page is intended as an introduction to working with binary data in JavaScript. Bun implements a number of data types and utilities for working with binary data, most of which are Web-standard. Any Bun-specific APIs will be noted as such.\nBelow is a quick \"cheat sheet\" that doubles as a table of contents. Click an item in the left column to jump to that section.\n{% table %}\n---\nA family of classes that provide an -like interface for interacting with binary data. Includes , , , and more.\n---\nA subclass of  that implements a wide range of convenience methods. Unlike the other elements in this table, this is a Node.js API (which Bun implements). It can't be used in the browser.\n---\nA class that provides a  API for writing some number of bytes to an  at a particular byte offset. Often used reading or writing binary protocols.\n---\nA readonly blob of binary data usually representing a file. Has a MIME , a , and methods for converting to , , and string.\n---\n<!-- - \n_Browser only_. A subclass of  that represents a file. Has a  and  timestamp. There is experimental support in Node.js v20; Bun does not support  yet; most of its functionality is provided by .\n--- -->\n_Bun only_. A subclass of  that represents a lazily-loaded file on disk. Created with .\n{% /table %}\n and views\nUntil 2009, there was no language-native way to store and manipulate binary data in JavaScript. ECMAScript v5 introduced a range of new mechanisms for this. The most fundamental building block is , a simple data structure that represents a sequence of bytes in memory.\n`ts\n// this buffer can store 8 bytes\nconst buf = new ArrayBuffer(8);\n`\nDespite the name, it isn't an array and supports none of the array methods and operators one might expect. In fact, there is no way to directly read or write values from an . There's very little you can do with one except check its size and create \"slices\" from it.\n`ts\nconst buf = new ArrayBuffer(8);\nbuf.byteLength; // => 8\nconst slice = buf.slice(0, 4); // returns new ArrayBuffer\nslice.byteLength; // => 4\n`\nTo do anything interesting we need a construct known as a \"view\". A view is a class that _wraps_ an  instance and lets you read and manipulate the underlying data. There are two types of views: _typed arrays_ and .\nThe  class is a lower-level interface for reading and manipulating the data in an .\nBelow we create a new  and set the first byte to 5.\n`ts\nconst buf = new ArrayBuffer(4);\n// [0x0, 0x0, 0x0, 0x0]\nconst dv = new DataView(buf);\ndv.setUint8(0, 3); // write value 3 at byte offset 0\ndv.getUint8(0); // => 3\n// [0x11, 0x0, 0x0, 0x0]\n`\nNow lets write a  at byte offset . This requires two bytes. We're using the value , which is ; in bytes, that's .\n`ts\ndv.setUint16(1, 513);\n// [0x11, 0x10, 0x1, 0x0]\nconsole.log(dv.getUint16(1)); // => 513\n`\nWe've now assigned a value to the first three bytes in our underlying . Even though the second and third bytes were created using , we can still read each of its component bytes using .\n`ts\nconsole.log(dv.getUint8(1)); // => 2\nconsole.log(dv.getUint8(2)); // => 1\n`\nAttempting to write a value that requires more space than is available in the underlying  will cuase an error. Below we attempt to write a  (which requires 8 bytes) at byte offset , but there are only four total bytes in the buffer.\n`ts\ndv.setFloat64(0, 3.1415);\n// ^ RangeError: Out of bounds access\n`\nThe following methods are available on :\n{% table %}\nGetters\nSetters\n---\n---\n---\n---\n---\n---\n---\n---\n---\n---\n{% /table %}\nTyped arrays are a family of classes that provide an -like interface for interacting with data in an . Whereas a  lets you write numbers of varying size at a particular offset, a  interprets the underlying bytes as an array of numbers, each of a fixed size.\n{% callout %}\nNote \u2014 It's common to refer to this family of classes collectively by their shared superclass . This class as _internal_ to JavaScript; you can't directly create instances of it, and  is not defined in the global scope. Think of it as an  or an abstract class.\n{% /callout %}\n`ts\nconst buffer = new ArrayBuffer(3);\nconst arr = new Uint8Array(buffer);\n// contents are initialized to zero\nconsole.log(arr); // Uint8Array(3) [0, 0, 0]\n// assign values like an array\narr[0] = 0;\narr[1] = 10;\narr[2] = 255;\narr[3] = 255; // no-op, out of bounds\n`\nWhile an  is a generic sequence of bytes, these typed array classes interpret the bytes as an array of numbers of a given byte size.\nThe top row contains the raw bytes, and the later rows contain how these bytes will be interpreted when _viewed_ using different typed array classes.\nThe following classes are typed arrays, along with a description of how they interpret the bytes in an :\n{% table %}\nClass\nDescription\n---\nEvery one (1) byte is interpreted as an unsigned 8-bit integer. Range 0 to 255.\n---\nEvery two (2) bytes are interpreted as an unsigned 16-bit integer. Range 0 to 65535.\n---\nEvery four (4) bytes are interpreted as an unsigned 32-bit integer. Range 0 to 4294967295.\n---\nEvery one (1) byte is interpreted as a signed 8-bit integer. Range -128 to 127.\n---\nEvery two (2) bytes are interpreted as a signed 16-bit integer. Range -32768 to 32767.\n---\nEvery four (4) bytes are interpreted as a signed 32-bit integer. Range -2147483648 to 2147483647.\n---\nEvery four (4) bytes are interpreted as a 32-bit floating point number. Range -3.4e38 to 3.4e38.\n---\nEvery eight (8) bytes are interpreted as a 64-bit floating point number. Range -1.7e308 to 1.7e308.\n---\nEvery eight (8) bytes are interpreted as an unsigned . Range -9223372036854775808 to 9223372036854775807 (though  is capable of representing larger numbers).\n---\nEvery eight (8) bytes are interpreted as an unsigned . Range 0 to 18446744073709551615 (though  is capable of representing larger numbers).\n---\nSame as , but automatically \"clamps\" to the range 0-255 when assigning a value to an element.\n{% /table %}\nThe table below demonstrates how the bytes in an  are interpreted when viewed using different typed array classes.\n{% table %}\n---\n---\n0\n1\n2\n3\n4\n5\n6\n7\n---\n256 () {% colspan=2 %}\n770 () {% colspan=2 %}\n1284 () {% colspan=2 %}\n1798 () {% colspan=2 %}\n---\n50462976 {% colspan=4 %}\n117835012 {% colspan=4 %}\n---\n506097522914230528n {% colspan=8 %}\n{% /table %}\nTo create a typed array from a pre-defined :\n`ts\n// create typed array from ArrayBuffer\nconst buf = new ArrayBuffer(10);\nconst arr = new Uint8Array(buf);\narr[0] = 30;\narr[1] = 60;\n// all elements are initialized to zero\nconsole.log(arr); // => Uint8Array(10) [ 30, 60, 0, 0, 0, 0, 0, 0, 0, 0 ];\n`\nIf we tried to instantiate a  from this same , we'd get an error.\n`ts\nconst buf = new ArrayBuffer(10);\nconst arr = new Uint32Array(buf);\n//          ^  RangeError: ArrayBuffer length minus the byteOffset\n//             is not a multiple of the element size\n`\nA  value requires four bytes (16 bits). Because the  is 10 bytes long, there's no way to cleanly divide its contents into 4-byte chunks.\nTo fix this, we can create a typed array over a particular \"slice\" of an . The  below only \"views\" the _first_ 8 bytes of the underlying . To achieve these, we specify a  of  and a  of , which indicates the number of  numbers we want our array to hold.\n`ts\n// create typed array from ArrayBuffer slice\nconst buf = new ArrayBuffer(10);\nconst arr = new Uint32Array(buf, 0, 2);\n/\n  buf    _ _ _ _ _ _ _ _ _ _    10 bytes\n  arr   [_______,_______]       2 4-byte elements\n/\narr.byteOffset; // 0\narr.length; // 2\n`\nYou don't need to explicitly create an  instance; you can instead directly specify a length in the typed array constructor:\n`ts\nconst arr2 = new Uint8Array(5);\n// all elements are initialized to zero\n// => Uint8Array(5) [0, 0, 0, 0, 0]\n`\nTyped arrays can also be instantiated directly from an array of numbers, or another typed array:\n`ts\n// from an array of numbers\nconst arr1 = new Uint8Array([0, 1, 2, 3, 4, 5, 6, 7]);\narr1[0]; // => 0;\narr1[7]; // => 7;\n// from another typed array\nconst arr2 = new Uint8Array(arr);\n`\nBroadly speaking, typed arrays provide the same methods as regular arrays, with a few exceptions. For example,  and  are not available on typed arrays, because they would require resizing the underlying .\n`ts\nconst arr = new Uint8Array([0, 1, 2, 3, 4, 5, 6, 7]);\n// supports common array methods\narr.filter(n => n > 128); // Uint8Array(1) [255]\narr.map(n => n  2); // Uint8Array(8) [0, 2, 4, 6, 8, 10, 12, 14]\narr.reduce((acc, n) => acc + n, 0); // 28\narr.forEach(n => console.log(n)); // 0 1 2 3 4 5 6 7\narr.every(n => n < 10); // true\narr.find(n => n > 5); // 6\narr.includes(5); // true\narr.indexOf(5); // 5\n`\nRefer to the MDN documentation for more information on the properties and methods of typed arrays.\nIt's worth specifically highlighting , as it represents a classic \"byte array\"\u2014a sequence of 8-bit unsigned integers between 0 and 255. This is the most common typed array you'll encounter in JavaScript.\nIt is the return value of , and the input type of , two utility classes designed to translate strings and various binary encodings, most notably .\n`ts\nconst encoder = new TextEncoder();\nconst bytes = encoder.encode(\"hello world\");\n// => Uint8Array(11) [ 104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100 ]\nconst decoder = new TextDecoder();\nconst text = decoder.decode(bytes);\n// => hello world\n`\nBun implements , a Node.js API for working with binary data that pre-dates the introduction of typed arrays in the JavaScript spec. It has since been re-implemented as a subclass of . It provides a wide range of methods, including several Array-like and -like methods.\n`ts\nconst buf = Buffer.from(\"hello world\");\n// => Buffer(16) [ 116, 104, 105, 115, 32, 105, 115, 32, 97, 32, 115, 116, 114, 105, 110, 103 ]\nbuf.length; // => 11\nbuf[0]; // => 104, ascii for 'h'\nbuf.writeUInt8(72, 0); // => ascii for 'H'\nconsole.log(buf.toString());\n// => Hello world\n`\nFor complete documentation, refer to the Node.js documentation.\n is a Web API commonly used for representing files.  was initially implemented in browsers (unlike  which is part of JavaScript itself), but it is now supported in Node and Bun.\nIt isn't common to directly create  instances. More often, you'll recieve instances of  from an external source (like an  element in the browser) or library. That said, it is possible to create a  from one or more string or binary \"blob parts\".\n`ts\nconst blob = new Blob([\"<html>Hello</html>\"], {\n  type: \"text/html\",\n});\nblob.type; // => text/html\nblob.size; // => 19\n`\nThese parts can be , , , , or other  instances. The blob parts are concatenated together in the order they are provided.\n`ts\nconst blob = new Blob([\n  \"<html>\",\n  new Blob([\"<body>\"]),\n  new Uint8Array([104, 101, 108, 108, 111]), // \"hello\" in binary\n  \"</body></html>\",\n]);\n`\nThe contents of a  can be asynchronously read in various formats.\n`ts\nawait blob.text(); // => <html><body>hello</body></html>\nawait blob.arrayBuffer(); // => ArrayBuffer (copies contents)\nawait blob.stream(); // => ReadableStream\n`\n is a subclass of  used to represent a lazily-loaded file on disk. Like , it adds a  and  property. Unlike , it does not require the file to be loaded into memory.\n`ts\nconst file = Bun.file(\"index.txt\");\n// => BunFile\n`\n{% callout %}\nBrowser only. Experimental support in Node.js 20.\n{% /callout %}\n is a subclass of  that adds a  and  property. It's commonly used in the browser to represent files uploaded via a  element. Node.js and Bun implement .\n`ts\n// on browser!\n// <input type=\"file\" id=\"file\" />\nconst files = document.getElementById(\"file\").files;\n// => File[]\n`\n`ts\nconst file = new File([\"<html>Hello</html>\"], \"index.html\", {\n  type: \"text/html\",\n});\n`\nRefer to the MDN documentation for complete docs information.\nStreams\nStreams are an important abstraction for working with binary data without loading it all into memory at once. They are commonly used for reading and writing files, sending and receiving network requests, and processing large amounts of data.\nBun implements the Web APIs  and .\n{% callout %}\nBun also implements the  module, including , , and . For complete documentation, refer to the Node.js docs.\n{% /callout %}\nTo create a simple readable stream:\n`ts\nconst stream = new ReadableStream({\n  start(controller) {\n    controller.enqueue(\"hello\");\n    controller.enqueue(\"world\");\n    controller.close();\n  },\n});\n`\nThe contents of this stream can be read chunk-by-chunk with  syntax.\n`ts\nfor await (const chunk of stream) {\n  console.log(chunk);\n  // => \"hello\"\n  // => \"world\"\n}\n`\nFor a more complete discusson of streams in Bun, see API > Streams.\nConversion\nConverting from one binary format to another is a common task. This section is intended as a reference.\nFrom \nSince  stores the data that underlies other binary structures like , the snippets below are not _converting_ from  to another format. Instead, they are _creating_ a new instance using the data stored underlying data.\nTo \n`ts\nnew Uint8Array(buf);\n`\nTo \n`ts\nnew DataView(buf);\n`\nTo \n`ts\n// create Buffer over entire ArrayBuffer\nBuffer.from(buf);\n// create Buffer over a slice of the ArrayBuffer\nBuffer.from(buf, 0, 10);\n`\nTo \n`ts\nnew TextDecoder().decode(buf);\n`\nTo \n`ts\nArray.from(new Uint8Array(buf));\n`\nTo \n`ts\nnew Blob([buf], { type: \"text/plain\" });\n`\n<!-- To \n`ts\nnew File([buf], \"filename.txt\", { type: \"text/plain\", lastModified: Date.now() });\n` -->\nTo \nThe following snippet creates a  and enqueues the entire  as a single chunk.\n`ts\nnew ReadableStream({\n  start(controller) {\n    controller.enqueue(buf);\n    controller.close();\n  },\n});\n`\n{% details summary=\"With chunking\" %}\nTo stream the  in chunks, use a  view and enqueue each chunk.\n`ts\nconst view = new Uint8Array(buf);\nconst chunkSize = 1024;\nnew ReadableStream({\n  start(controller) {\n    for (let i = 0; i < view.length; i += chunkSize) {\n      controller.enqueue(view.slice(i, i + chunkSize));\n    }\n    controller.close();\n  },\n});\n`\n{% /details %}\nFrom \nTo \nThis retrieves the underlying . Note that a  can be a view of a _slice_ of the underlying buffer, so the sizes may differ.\n`ts\narr.buffer;\n`\nTo \nTo creates a  over the same byte range as the TypedArray.\n`ts\nnew DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n`\nTo \n`ts\nBuffer.from(arr);\n`\nTo \n`ts\nnew TextDecoder().decode(arr);\n`\nTo \n`ts\nArray.from(arr);\n`\nTo \n`ts\nnew Blob([arr.buffer], { type: \"text/plain\" });\n`\n<!-- To \n`ts\nnew File([arr.buffer], \"filename.txt\", { type: \"text/plain\", lastModified: Date.now() });\n` -->\nTo \n`ts\nnew ReadableStream({\n  start(controller) {\n    controller.enqueue(arr);\n    controller.close();\n  },\n});\n`\n{% details summary=\"With chunking\" %}\nTo stream the  in chunks, split the  into chunks and enqueue each one individually.\n`ts\nnew ReadableStream({\n  start(controller) {\n    for (let i = 0; i < arr.length; i += chunkSize) {\n      controller.enqueue(arr.slice(i, i + chunkSize));\n    }\n    controller.close();\n  },\n});\n`\n{% /details %}\nFrom \nTo \n`ts\nview.buffer;\n`\nTo \nOnly works if the  of the  is a multiple of the  of the  subclass.\n`ts\nnew Uint8Array(view.buffer, view.byteOffset, view.byteLength);\nnew Uint16Array(view.buffer, view.byteOffset, view.byteLength / 2);\nnew Uint32Array(view.buffer, view.byteOffset, view.byteLength / 4);\n// etc...\n`\nTo \n`ts\nBuffer.from(view.buffer, view.byteOffset, view.byteLength);\n`\nTo \n`ts\nnew TextDecoder().decode(view);\n`\nTo \n`ts\nArray.from(view);\n`\nTo \n`ts\nnew Blob([view.buffer], { type: \"text/plain\" });\n`\n<!-- To \n`ts\nnew File([view.buffer], \"filename.txt\", { type: \"text/plain\", lastModified: Date.now() });\n` -->\nTo \n`ts\nnew ReadableStream({\n  start(controller) {\n    controller.enqueue(view.buffer);\n    controller.close();\n  },\n});\n`\n{% details summary=\"With chunking\" %}\nTo stream the  in chunks, split the  into chunks and enqueue each one individually.\n`ts\nnew ReadableStream({\n  start(controller) {\n    for (let i = 0; i < view.byteLength; i += chunkSize) {\n      controller.enqueue(view.buffer.slice(i, i + chunkSize));\n    }\n    controller.close();\n  },\n});\n`\n{% /details %}\nFrom \nTo \n`ts\nbuf.buffer;\n`\nTo \n`ts\nnew Uint8Array(buf);\n`\nTo \n`ts\nnew DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n`\nTo \n`ts\nbuf.toString();\n`\nTo \n`ts\nArray.from(buf);\n`\nTo \n`ts\nnew Blob([buf], { type: \"text/plain\" });\n`\n<!-- To \n`ts\nnew File([buf], \"filename.txt\", { type: \"text/plain\", lastModified: Date.now() });\n` -->\nTo \n`ts\nnew ReadableStream({\n  start(controller) {\n    controller.enqueue(buf);\n    controller.close();\n  },\n});\n`\n{% details summary=\"With chunking\" %}\nTo stream the  in chunks, split the  into chunks and enqueue each one individually.\n`ts\nnew ReadableStream({\n  start(controller) {\n    for (let i = 0; i < buf.length; i += chunkSize) {\n      controller.enqueue(buf.slice(i, i + chunkSize));\n    }\n    controller.close();\n  },\n});\n`\n{% /details %}\nFrom \nTo \nThe  class provides a convenience method for this purpose.\n`ts\nawait blob.arrayBuffer();\n`\nTo \n`ts\nnew Uint8Array(await blob.arrayBuffer());\n`\nTo \n`ts\nnew DataView(await blob.arrayBuffer());\n`\nTo \n`ts\nBuffer.from(await blob.arrayBuffer());\n`\nTo \n`ts\nawait blob.text();\n`\nTo \n`ts\nArray.from(new Uint8Array(await blob.arrayBuffer()));\n`\nTo \n`ts\nblob.stream();\n`\n<!-- From  -->\nFrom \nIt's common to use  as a convenient intermediate representation to make it easier to convert  to other formats.\n`ts\nstream; // ReadableStream\nconst buffer = new Response(stream).arrayBuffer();\n`\nHowever this approach is verbose and adds overhead that slows down overall performance unnecessarily. Bun implements a set of optimized convenience functions for converting  various binary formats.\nTo \n`ts\n// with Response\nnew Response(stream).arrayBuffer();\n// with Bun function\nBun.readableStreamToArrayBuffer(stream);\n`\nTo \n`ts\n// with Response\nconst buf = await new Response(stream).arrayBuffer();\nnew Uint8Array(buf);\n// with Bun function\nnew Uint8Array(Bun.readableStreamToArrayBuffer(stream));\n`\nTo \n`ts\n// with Response\nconst buf = await new Response(stream).arrayBuffer();\nnew DataView(buf);\n// with Bun function\nnew DataView(Bun.readableStreamToArrayBuffer(stream));\n`\nTo \n`ts\n// with Response\nconst buf = await new Response(stream).arrayBuffer();\nBuffer.from(buf);\n// with Bun function\nBuffer.from(Bun.readableStreamToArrayBuffer(stream));\n`\nTo \n`ts\n// with Response\nnew Response(stream).text();\n// with Bun function\nawait Bun.readableStreamToText(stream);\n`\nTo \n`ts\n// with Response\nconst buf = await new Response(stream).arrayBuffer();\nArray.from(new Uint8Array(buf));\n// with Bun function\nArray.from(new Uint8Array(Bun.readableStreamToArrayBuffer(stream)));\n`\nBun provides a utility for resolving a  to an array of its chunks. Each chunk may be a string, typed array, or .\n`ts\n// with Bun function\nBun.readableStreamToArray(stream);\n`\nTo \n`ts\nnew Response(stream).blob();\n`\n<!-- To \n`ts\nnew Response(stream)\n  .blob()\n  .then(blob => new File([blob], \"filename.txt\", { type: \"text/plain\", lastModified: Date.now() }));\n` -->\nTo \nTo split a  into two streams that can be consumed independently:\n`ts\nconst [a, b] = stream.tee();\n`\n<!-- - Use Buffer\nTextEncoder\nReadableStream\nAsyncIterator\nTypedArray vs ArrayBuffer vs DataView\nBun.indexOfLine\n\u201cdirect\u201d readablestream\n  - readable stream has assumptions about\n  - its very generic\n  - all data is copies and queued\n  - direct : no queueing\n  - just a write function\n  - you can write strings\n  - more synchronous\n  - corking works better -->"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/console.md"}, {"role": "assistant", "content": "{% callout %}\nNote \u2014 Bun provides a browser- and Node.js-compatible console global. This page only documents Bun-native APIs.\n{% /callout %}\nIn Bun, the  object can be used as an  to sequentially read lines from .\n`ts\nfor await (const line of console) {\n  console.log(line);\n}\n`\nThis is useful for implementing interactive programs, like the following addition calculator.\n`ts#adder.ts\nconsole.log();\nconsole.write();\nlet count = 0;\nfor await (const line of console) {\n  count += Number(line);\n  console.write();\n}\n`\nTo run the file:\n`bash\n$ bun adder.ts\nLet's add some numbers!\nCount: 0\nCount: 5\nCount: 10\nCount: 15\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/dns.md"}, {"role": "assistant", "content": "Bun implements the  module.\n`ts\nimport  as dns from \"node:dns\";\nconst addrs = await dns.promises.resolve4(\"bun.sh\", { ttl: true });\nconsole.log(addrs);\n// => [{ address: \"172.67.161.226\", family: 4, ttl: 0 }, ...]\n`\n<!--\n - lookup a domain\n includes utilities to make DNS requests, similar to . As of Bun v0.5.0, the only implemented function is , though more will be implemented soon.\nYou can lookup the IP addresses of a hostname by using .\n`ts\nimport { dns } from \"bun\";\nconst [{ address }] = await dns.lookup(\"example.com\");\nconsole.log(address); // \"93.184.216.34\"\n`\nIf you need to limit IP addresses to either IPv4 or IPv6, you can specify the  as an option.\n`ts\nimport { dns } from \"bun\";\nconst [{ address }] = await dns.lookup(\"example.com\", { family: 6 });\nconsole.log(address); // \"2606:2800:220:1:248:1893:25c8:1946\"\n`\nBun supports three backends for DNS resolution:\n - This is the default on Linux, and it uses the c-ares library to perform DNS resolution.\n - Uses the system's non-blocking DNS resolver, if available. Otherwise, falls back to . This is the default on macOS, and the same as  on Linux.\n - Uses the POSIX standard  function, which may cause performance issues under concurrent load.\nYou can choose a particular backend by specifying  as an option.\n`ts\nimport { dns } from \"bun\";\nconst [{ address, ttl }] = await dns.lookup(\"example.com\", {\n  backend: \"c-ares\"\n});\nconsole.log(address); // \"93.184.216.34\"\nconsole.log(ttl); // 21237\n`\nNote: the  property is only accurate when the  is c-ares. Otherwise,  will be .\nThis was added in Bun v0.5.0. -->"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/ffi.md"}, {"role": "assistant", "content": "Use the built-in  module to efficiently call native libraries from JavaScript. It works with languages that support the C ABI (Zig, Rust, C/C++, C#, Nim, Kotlin, etc).\nUsage ()\nTo print the version number of :\n`ts\nimport { dlopen, FFIType, suffix } from \"bun:ffi\";\n//  is either \"dylib\", \"so\", or \"dll\" depending on the platform\n// you don't have to use \"suffix\", it's just there for convenience\nconst path = ;\nconst {\n  symbols: {\n    sqlite3_libversion, // the function to call\n  },\n} = dlopen(\n  path, // a library name or file path\n  {\n    sqlite3_libversion: {\n      // no arguments, returns a string\n      args: [],\n      returns: FFIType.cstring,\n    },\n  },\n);\nconsole.log();\n`\nPerformance\nAccording to our benchmark,  is roughly 2-6x faster than Node.js FFI via .\n{% image src=\"/images/ffi.png\" height=\"400\" /%}\nBun generates & just-in-time compiles C bindings that efficiently convert values between JavaScript types and native types. To compile C, Bun embeds TinyCC, a small and fast C compiler.\nUsage\nZig\n`zig\n// add.zig\npub export fn add(a: i32, b: i32) i32 {\n  return a + b;\n}\n`\nTo compile:\n`bash\n$ zig build-lib add.zig -dynamic -OReleaseFast\n`\nPass a path to the shared library and a map of symbols to import into :\n`ts\nimport { dlopen, FFIType, suffix } from \"bun:ffi\";\nconst path = ;\nconst lib = dlopen(path, {\n  add: {\n    args: [FFIType.i32, FFIType.i32],\n    returns: FFIType.i32,\n  },\n});\nlib.symbols.add(1, 2);\n`\nRust\n`rust\n// add.rs\n#[no_mangle]\npub extern \"C\" fn add(a: isize, b: isize) -> isize {\n    a + b\n}\n`\nTo compile:\n`bash\n$ rustc --crate-type cdylib add.rs\n`\nFFI types\nThe following  values are supported.\n|  | C Type         | Aliases                     |\n| --------- | -------------- | --------------------------- |\n| cstring   |         |                             |\n| function  |  | ,             |\n| ptr       |         | , ,  |\n| i8        |        |                     |\n| i16       |       |                    |\n| i32       |       | ,             |\n| i64       |       |                    |\n| i64_fast  |       |                             |\n| u8        |       |                    |\n| u16       |      |                   |\n| u32       |      |                   |\n| u64       |      |                   |\n| u64_fast  |      |                             |\n| f32       |         |                      |\n| f64       |        |                     |\n| bool      |          |                             |\n| char      |          |                             |\nStrings\nJavaScript strings and C-like strings are different, and that complicates using strings with native libraries.\n{% details summary=\"How are JavaScript strings and C strings different?\" %}\nJavaScript strings:\nUTF16 (2 bytes per letter) or potentially latin1, depending on the JavaScript engine &amp; what characters are used\n stored separately\nImmutable\nC strings:\nUTF8 (1 byte per letter), usually\nThe length is not stored. Instead, the string is null-terminated which means the length is the index of the first  it finds\nMutable\n{% /details %}\nTo solve this,  exports  which extends JavaScript's built-in  to support null-terminated strings and add a few extras:\n`ts\nclass CString extends String {\n  /\n    Given a , this will automatically search for the closing  character and transcode from UTF-8 to UTF-16 if necessary.\n   /\n  constructor(ptr: number, byteOffset?: number, byteLength?: number): string;\n  /\n    The ptr to the C string\n   \n    This  instance is a clone of the string, so it\n    is safe to continue using this instance after the  has been\n    freed.\n   /\n  ptr: number;\n  byteOffset?: number;\n  byteLength?: number;\n}\n`\nTo convert from a null-terminated string pointer to a JavaScript string:\n`ts\nconst myString = new CString(ptr);\n`\nTo convert from a pointer with a known length to a JavaScript string:\n`ts\nconst myString = new CString(ptr, 0, byteLength);\n`\nThe  constructor clones the C string, so it is safe to continue using  after  has been freed.\n`ts\nmy_library_free(myString.ptr);\n// this is safe because myString is a clone\nconsole.log(myString);\n`\nWhen used in ,  coerces the pointer to a JavaScript . When used in ,  is identical to .\nFunction pointers\n{% callout %}\nNote \u2014 Async functions are not yet supported.\n{% /callout %}\nTo call a function pointer from JavaScript, use . This is useful if using Node-API (napi) with Bun, and you've already loaded some symbols.\n`ts\nimport { CFunction } from \"bun:ffi\";\nlet myNativeLibraryGetVersion = / somehow, you got this pointer /\nconst getVersion = new CFunction({\n  returns: \"cstring\",\n  args: [],\n  ptr: myNativeLibraryGetVersion,\n});\ngetVersion();\n`\nIf you have multiple function pointers, you can define them all at once with :\n`ts\nimport { linkSymbols } from \"bun:ffi\";\n// getVersionPtrs defined elsewhere\nconst [majorPtr, minorPtr, patchPtr] = getVersionPtrs();\nconst lib = linkSymbols({\n  // Unlike with dlopen(), the names here can be whatever you want\n  getMajor: {\n    returns: \"cstring\",\n    args: [],\n    // Since this doesn't use dlsym(), you have to provide a valid ptr\n    // That ptr could be a number or a bigint\n    // An invalid pointer will crash your program.\n    ptr: majorPtr,\n  },\n  getMinor: {\n    returns: \"cstring\",\n    args: [],\n    ptr: minorPtr,\n  },\n  getPatch: {\n    returns: \"cstring\",\n    args: [],\n    ptr: patchPtr,\n  },\n});\nconst [major, minor, patch] = [lib.symbols.getMajor(), lib.symbols.getMinor(), lib.symbols.getPatch()];\n`\nCallbacks\nUse  to create JavaScript callback functions that can be passed to C/FFI functions. The C/FFI function can call into the JavaScript/TypeScript code. This is useful for asynchronous code or whenever you want to call into JavaScript code from C.\n`ts\nimport { dlopen, JSCallback, ptr, CString } from \"bun:ffi\";\nconst {\n  symbols: { search },\n  close,\n} = dlopen(\"libmylib\", {\n  search: {\n    returns: \"usize\",\n    args: [\"cstring\", \"callback\"],\n  },\n});\nconst searchIterator = new JSCallback((ptr, length) => /hello/.test(new CString(ptr, length)), {\n  returns: \"bool\",\n  args: [\"ptr\", \"usize\"],\n});\nconst str = Buffer.from(\"wwutwutwutwutwutwutwutwutwutwutut\\0\", \"utf8\");\nif (search(ptr(str), searchIterator)) {\n  // found a match!\n}\n// Sometime later:\nsetTimeout(() => {\n  searchIterator.close();\n  close();\n}, 5000);\n`\nWhen you're done with a JSCallback, you should call  to free the memory.\n{% callout %}\n\u26a1\ufe0f Performance tip \u2014 For a slight performance boost, directly pass  instead of the  object:\n`ts\nconst onResolve = new JSCallback(arg => arg === 42, {\n  returns: \"bool\",\n  args: [\"i32\"],\n});\nconst setOnResolve = new CFunction({\n  returns: \"bool\",\n  args: [\"function\"],\n  ptr: myNativeLibrarySetOnResolve,\n});\n// This code runs slightly faster:\nsetOnResolve(onResolve.ptr);\n// Compared to this:\nsetOnResolve(onResolve);\n`\n{% /callout %}\nPointers\nBun represents pointers>) as a  in JavaScript.\n{% details summary=\"How does a 64 bit pointer fit in a JavaScript number?\" %}\n64-bit processors support up to 52 bits of addressable space. JavaScript numbers support 53 bits of usable space, so that leaves us with about 11 bits of extra space.\nWhy not ?  is slower. JavaScript engines allocate a separate  which means they can't fit into a regular JavaScript value. If you pass a  to a function, it will be converted to a \n{% /details %}\nTo convert from a  to a pointer:\n`ts\nimport { ptr } from \"bun:ffi\";\nlet myTypedArray = new Uint8Array(32);\nconst myPtr = ptr(myTypedArray);\n`\nTo convert from a pointer to an :\n`ts\nimport { ptr, toArrayBuffer } from \"bun:ffi\";\nlet myTypedArray = new Uint8Array(32);\nconst myPtr = ptr(myTypedArray);\n// toArrayBuffer accepts a  and \n// if  is not provided, it is assumed to be a null-terminated pointer\nmyTypedArray = new Uint8Array(toArrayBuffer(myPtr, 0, 32), 0, 32);\n`\nTo read data from a pointer, you have two options. For long-lived pointers, use a :\n`ts\nimport { toArrayBuffer } from \"bun:ffi\";\nlet myDataView = new DataView(toArrayBuffer(myPtr, 0, 32));\nconsole.log(\n  myDataView.getUint8(0, true),\n  myDataView.getUint8(1, true),\n  myDataView.getUint8(2, true),\n  myDataView.getUint8(3, true),\n);\n`\nFor short-lived pointers, use :\n`ts\nimport { read } from \"bun:ffi\";\nconsole.log(\n  // ptr, byteOffset\n  read.u8(myPtr, 0),\n  read.u8(myPtr, 1),\n  read.u8(myPtr, 2),\n  read.u8(myPtr, 3),\n);\n`\nThe  function behaves similarly to , but it's usually faster because it doesn't need to create a  or .\n|  |  function |\n| --------- | --------------- |\n| ptr       |       |\n| i8        |        |\n| i16       |       |\n| i32       |       |\n| i64       |       |\n| u8        |        |\n| u16       |       |\n| u32       |       |\n| u64       |       |\n| f32       |       |\n| f64       |       |\nMemory management\n does not manage memory for you. You must free the memory when you're done with it.\nFrom JavaScript\nIf you want to track when a  is no longer in use from JavaScript, you can use a FinalizationRegistry.\nFrom C, Rust, Zig, etc\n{% callout %}\nNote \u2014 Available in Bun v0.1.8 and later.\n{% /callout %}\nIf you want to track when a  is no longer in use from C or FFI, you can pass a callback and an optional context pointer to  or . This function is called at some point later, once the garbage collector frees the underlying  JavaScript object.\nThe expected signature is the same as in JavaScriptCore's C API:\n`c\ntypedef void (JSTypedArrayBytesDeallocator)(void bytes, void deallocatorContext);\n`\n`ts\nimport { toArrayBuffer } from \"bun:ffi\";\n// with a deallocatorContext:\ntoArrayBuffer(\n  bytes,\n  byteOffset,\n  byteLength,\n  // this is an optional pointer to a callback\n  deallocatorContext,\n  // this is a pointer to a function\n  jsTypedArrayBytesDeallocator,\n);\n// without a deallocatorContext:\ntoArrayBuffer(\n  bytes,\n  byteOffset,\n  byteLength,\n  // this is a pointer to a function\n  jsTypedArrayBytesDeallocator,\n);\n`\nMemory safety\nUsing raw pointers outside of FFI is extremely not recommended. A future version of Bun may add a CLI flag to disable .\nPointer alignment\nIf an API expects a pointer sized to something other than  or , make sure the  is also that size. A  is not exactly the same as  due to alignment.\nPassing a pointer\nWhere FFI functions expect a pointer, pass a  of equivalent size:\n`ts\nimport { dlopen, FFIType } from \"bun:ffi\";\nconst {\n  symbols: { encode_png },\n} = dlopen(myLibraryPath, {\n  encode_png: {\n    // FFIType's can be specified as strings too\n    args: [\"ptr\", \"u32\", \"u32\"],\n    returns: FFIType.ptr,\n  },\n});\nconst pixels = new Uint8ClampedArray(128  128  4);\npixels.fill(254);\npixels.subarray(0, 32  32  2).fill(0);\nconst out = encode_png(\n  // pixels will be passed as a pointer\n  pixels,\n  128,\n  128,\n);\n`\nThe auto-generated wrapper converts the pointer to a .\n{% details summary=\"Hardmode\" %}\nIf you don't want the automatic conversion or you want a pointer to a specific byte offset within the , you can also directly get the pointer to the :\n`ts\nimport { dlopen, FFIType, ptr } from \"bun:ffi\";\nconst {\n  symbols: { encode_png },\n} = dlopen(myLibraryPath, {\n  encode_png: {\n    // FFIType's can be specified as strings too\n    args: [\"ptr\", \"u32\", \"u32\"],\n    returns: FFIType.ptr,\n  },\n});\nconst pixels = new Uint8ClampedArray(128  128  4);\npixels.fill(254);\n// this returns a number! not a BigInt!\nconst myPtr = ptr(pixels);\nconst out = encode_png(\n  myPtr,\n  // dimensions:\n  128,\n  128,\n);\n`\n{% /details %}\nReading pointers\n`ts\nconst out = encode_png(\n  // pixels will be passed as a pointer\n  pixels,\n  // dimensions:\n  128,\n  128,\n);\n// assuming it is 0-terminated, it can be read like this:\nlet png = new Uint8Array(toArrayBuffer(out));\n// save it to disk:\nawait Bun.write(\"out.png\", png);\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/file-io.md"}, {"role": "assistant", "content": "{% callout %}\n<!-- Note \u2014 The  and  APIs documented on this page are heavily optimized and represent the recommended way to perform file-system tasks using Bun. Existing Node.js projects may use Bun's nearly complete implementation of the  module. -->\nNote \u2014 The  and  APIs documented on this page are heavily optimized and represent the recommended way to perform file-system tasks using Bun. For operations that are not yet available with , such as , you can use Bun's nearly complete implementation of the  module.\n{% /callout %}\nBun provides a set of optimized APIs for reading and writing files.\nReading files ()\nCreate a  instance with the  function. A  represents a lazily-loaded file; initializing it does not actually read the file from disk.\n`ts\nconst foo = Bun.file(\"foo.txt\"); // relative to cwd\nfoo.size; // number of bytes\nfoo.type; // MIME type\n`\nThe reference conforms to the  interface, so the contents can be read in various formats.\n`ts\nconst foo = Bun.file(\"foo.txt\");\nawait foo.text(); // contents as a string\nawait foo.stream(); // contents as ReadableStream\nawait foo.arrayBuffer(); // contents as ArrayBuffer\n`\nFile references can also be created using numerical file descriptors or  URLs.\n`ts\nBun.file(1234);\nBun.file(new URL(import.meta.url)); // reference to the current file\n`\nA  can point to a location on disk where a file does not exist.\n`ts\nconst notreal = Bun.file(\"notreal.txt\");\nnotreal.size; // 0\nnotreal.type; // \"text/plain;charset=utf-8\"\n`\nThe default MIME type is , but it can be overridden by passing a second argument to .\n`ts\nconst notreal = Bun.file(\"notreal.json\", { type: \"application/json\" });\nnotreal.type; // => \"application/json;charset=utf-8\"\n`\nFor convenience, Bun exposes ,  and  as instances of .\n`ts\nBun.stdin; // readonly\nBun.stdout;\nBun.stderr;\n`\nWriting files ()\nThe  function is a multi-tool for writing payloads of all kinds to disk.\nThe first argument is the  which can have any of the following types:\n: A path to a location on the file system. Use the  module to manipulate paths.\n: A  descriptor.\n: A file reference.\nThe second argument is the data to be written. It can be any of the following:\n (including )\n or \n (, et. al.)\nAll possible permutations are handled using the fastest available system calls on the current platform.\n{% details summary=\"See syscalls\" %}\n{% table %}\nOutput\nInput\nSystem call\nPlatform\n---\nfile\nfile\ncopy_file_range\nLinux\n---\nfile\npipe\nsendfile\nLinux\n---\npipe\npipe\nsplice\nLinux\n---\nterminal\nfile\nsendfile\nLinux\n---\nterminal\nterminal\nsendfile\nLinux\n---\nsocket\nfile or pipe\nsendfile (if http, not https)\nLinux\n---\nfile (doesn't exist)\nfile (path)\nclonefile\nmacOS\n---\nfile (exists)\nfile\nfcopyfile\nmacOS\n---\nfile\nBlob or string\nwrite\nmacOS\n---\nfile\nBlob or string\nwrite\nLinux\n{% /table %}\n{% /details %}\nTo write a string to disk:\n`ts\nconst data = ;\nawait Bun.write(\"output.txt\", data);\n`\nTo copy a file to another location on disk:\n`js\nconst input = Bun.file(\"input.txt\");\nconst output = Bun.file(\"output.txt\"); // doesn't exist yet!\nawait Bun.write(output, input);\n`\nTo write a byte array to disk:\n`ts\nconst encoder = new TextEncoder();\nconst data = encoder.encode(\"datadatadata\"); // Uint8Array\nawait Bun.write(\"output.txt\", data);\n`\nTo write a file to :\n`ts\nconst input = Bun.file(\"input.txt\");\nawait Bun.write(Bun.stdout, input);\n`\nTo write an HTTP response to disk:\n`ts\nconst response = await fetch(\"https://bun.sh\");\nawait Bun.write(\"index.html\", response);\n`\nIncremental writing with \nBun provides a native incremental file writing API called . To retrieve a  instance from a :\n`ts\nconst file = Bun.file(\"output.txt\");\nconst writer = file.writer();\n`\nTo incrementally write to the file, call .\n`ts\nconst file = Bun.file(\"output.txt\");\nconst writer = file.writer();\nwriter.write(\"it was the best of times\\n\");\nwriter.write(\"it was the worst of times\\n\");\n`\nThese chunks will be buffered internally. To flush the buffer to disk, use . This returns the number of flushed bytes.\n`ts\nwriter.flush(); // write buffer to disk\n`\nThe buffer will also auto-flush when the 's _high water mark_ is reached; that is, when its internal buffer is full. This value can be configured.\n`ts\nconst file = Bun.file(\"output.txt\");\nconst writer = file.writer({ highWaterMark: 1024  1024 }); // 1MB\n`\nTo flush the buffer and close the file:\n`ts\nwriter.end();\n`\nNote that, by default, the  process will stay alive until this  is explicitly closed with . To opt out of this behavior, you can \"unref\" the instance.\n`ts\nwriter.unref();\n// to \"re-ref\" it later\nwriter.ref();\n`\nBenchmarks\nThe following is a 3-line implementation of the Linux  command.\n`ts#cat.ts\n// Usage\n// $ bun ./cat.ts ./path-to-file\nimport { resolve } from \"path\";\nconst path = resolve(process.argv.at(-1));\nawait Bun.write(Bun.stdout, Bun.file(path));\n`\nTo run the file:\n`bash\n$ bun ./cat.ts ./path-to-file\n`\nIt runs 2x faster than GNU  for large files on Linux.\n{% image src=\"/images/cat.jpg\" /%}\nReference\n`ts\ninterface Bun {\n  stdin: BunFile;\n  stdout: BunFile;\n  stderr: BunFile;\n  file(path: string | number | URL, options?: { type?: string }): BunFile;\n  write(\n    destination: string | number | BunFile | URL,\n    input:\n      | string\n      | Blob\n      | ArrayBuffer\n      | SharedArrayBuffer\n      | TypedArray\n      | Response,\n  ): Promise<number>;\n}\ninterface BunFile {\n  readonly size: number;\n  readonly type: string;\n  text(): Promise<string>;\n  stream(): Promise<ReadableStream>;\n  arrayBuffer(): Promise<ArrayBuffer>;\n  json(): Promise<any>;\n  writer(params: { highWaterMark?: number }): FileSink;\n}\nexport interface FileSink {\n  write(\n    chunk: string | ArrayBufferView | ArrayBuffer | SharedArrayBuffer,\n  ): number;\n  flush(): number | Promise<number>;\n  end(error?: Error): number | Promise<number>;\n  start(options?: { highWaterMark?: number }): void;\n  ref(): void;\n  unref(): void;\n}\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/file-system-router.md"}, {"role": "assistant", "content": "Bun provides a fast API for resolving routes against file-system paths. This API is primarily intended for library authors. At the moment only Next.js-style file-system routing is supported, but other styles may be added in the future.\nNext.js-style\nThe  class can resolve routes against a  directory. (The Next.js 13  directory is not yet supported.) Consider the following  directory:\n`txt\npages\n\u251c\u2500\u2500 index.tsx\n\u251c\u2500\u2500 settings.tsx\n\u251c\u2500\u2500 blog\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 [slug].tsx\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 index.tsx\n\u2514\u2500\u2500 [[...catchall]].tsx\n`\nThe  can be used to resolve routes against this directory:\n`ts\nconst router = new Bun.FileSystemRouter({\n  style: \"nextjs\",\n  dir: \"./pages\",\n  origin: \"https://mydomain.com\",\n  assetPrefix: \"_next/static/\"\n});\nrouter.match(\"/\");\n// =>\n{\n  filePath: \"/path/to/pages/index.tsx\",\n  kind: \"exact\",\n  name: \"/\",\n  pathname: \"/\",\n  src: \"https://mydomain.com/_next/static/pages/index.tsx\"\n}\n`\nQuery parameters will be parsed and returned in the  property.\n`ts\nrouter.match(\"/settings?foo=bar\");\n// =>\n{\n  filePath: \"/Users/colinmcd94/Documents/bun/fun/pages/settings.tsx\",\n  kind: \"dynamic\",\n  name: \"/settings\",\n  pathname: \"/settings?foo=bar\",\n  src: \"https://mydomain.com/_next/static/pages/settings.tsx\"\n  query: {\n    foo: \"bar\"\n  }\n}\n`\nThe router will automatically parse URL parameters and return them in the  property:\n`ts\nrouter.match(\"/blog/my-cool-post\");\n// =>\n{\n  filePath: \"/Users/colinmcd94/Documents/bun/fun/pages/blog/[slug].tsx\",\n  kind: \"dynamic\",\n  name: \"/blog/[slug]\",\n  pathname: \"/blog/my-cool-post\",\n  src: \"https://mydomain.com/_next/static/pages/blog/[slug].tsx\"\n  params: {\n    slug: \"my-cool-post\"\n  }\n}\n`\nThe  method also accepts  and  objects. The  property will be used to resolve the route.\n`ts\nrouter.match(new Request(\"https://example.com/blog/my-cool-post\"));\n`\nThe router will read the directory contents on initialization. To re-scan the files, use the  method.\n`ts\nrouter.reload();\n`\nReference\n`ts\ninterface Bun {\n  class FileSystemRouter {\n    constructor(params: {\n      dir: string;\n      style: \"nextjs\";\n      origin?: string;\n      assetPrefix?: string;\n    });\n    reload(): void;\n    match(path: string | Request | Response): {\n      filePath: string;\n      kind: \"exact\" | \"catch-all\" | \"optional-catch-all\" | \"dynamic\";\n      name: string;\n      pathname: string;\n      src: string;\n      params?: Record<string, string>;\n      query?: Record<string, string>;\n    } | null\n  }\n}\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/file.md"}, {"role": "assistant", "content": "Bun.js has fast paths for common use cases that make Web APIs live up to the performance demands of servers and CLIs.\n returns a  that represents a lazily-loaded file.\nWhen you pass a file blob to , Bun automatically uses a faster system call:\n`js\nconst blob = Bun.file(\"input.txt\");\nawait Bun.write(\"output.txt\", blob);\n`\nOn Linux, this uses the  syscall and on macOS, this becomes  (or ).\n also supports  objects. It automatically converts to a .\n`js\n// Eventually, this will stream the response to disk but today it buffers\nawait Bun.write(\"index.html\", await fetch(\"https://example.com\"));\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/globals.md"}, {"role": "assistant", "content": "Bun implements the following globals.\n{% table %}\nGlobal\nSource\nNotes\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\nIntended for command-line tools\n---\nWeb\n&nbsp;\n---\nNode.js\nSee Node.js > \n---\nBun\nSubject to change as additional APIs are added\n---\nWeb\n&nbsp;\n---\nWeb\nIntended for command-line tools\n---\nNode.js\n&nbsp;\n---\nNode.js\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nBun\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\nAlso   .\n---\nWeb\n&nbsp;\n---\nNode.js\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nNode.js\nSee Node.js > .\n---\nCross-platform\nAliases to \n---\nWeb\n&nbsp;\n---\nCloudflare\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nNode.js\n&nbsp;\n---\nWeb\n&nbsp;\n---\nNode.js\nSee Node.js > \n---\nWeb\nIntended for command-line tools\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nNode.js\n&nbsp;\n---\nBun\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\nStage 3 proposal\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n---\nWeb\n&nbsp;\n{% /table %}"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/hashing.md"}, {"role": "assistant", "content": "{% callout %}\nBun implements the  and  functions from  in addition to the Bun-native APIs documented below.\n{% /callout %}\n{% callout %}\nNote \u2014 Added in Bun 0.6.8.\n{% /callout %}\n is a collection of utility functions for hashing and verifying passwords with various cryptographically secure algorithms.\n`ts\nconst password = \"super-secure-pa$$word\";\nconst hash = await Bun.password.hash(password);\n// => $argon2id$v=19$m=65536,t=2,p=1$tFq+9AVr1bfPxQdh6E8DQRhEXg/M/SqYCNu6gVdRRNs$GzJ8PuBi+K+BVojzPfS5mjnC8OpLGtv8KJqF99eP6a4\nconst isMatch = await Bun.password.verify(password, hash);\n// => true\n`\nThe second argument to  accepts a params object that lets you pick and configure the hashing algorithm.\n`ts\nconst password = \"super-secure-pa$$word\";\n// use argon2 (default)\nconst argonHash = await Bun.password.hash(password, {\n  algorithm: \"argon2id\", // \"argon2id\" | \"argon2i\" | \"argon2d\"\n  memoryCost: 4, // memory usage in kibibytes\n  timeCost: 3, // the number of iterations\n});\n// use bcrypt\nconst bcryptHash = await Bun.password.hash(password, {\n  algorithm: \"bcrypt\",\n  cost: 4, // number between 4-31\n});\n`\nThe algorithm used to create the hash is stored in the hash itself. When using , the returned hash is encoded in Modular Crypt Format for compatibility with most existing  implementations; with  the result is encoded in the newer PHC format.\nThe  function automatically detects the algorithm based on the input hash and use the correct verification method. It can correctly infer the algorithm from both PHC- or MCF-encoded hashes.\n`ts\nconst password = \"super-secure-pa$$word\";\nconst hash = await Bun.password.hash(password, {\n  / config /\n});\nconst isMatch = await Bun.password.verify(password, hash);\n// => true\n`\nSynchronous versions of all functions are also available. Keep in mind that these functions are computationally expensive, so using a blocking API may degrade application performance.\n`ts\nconst password = \"super-secure-pa$$word\";\nconst hash = Bun.password.hashSync(password, {\n  / config /\n});\nconst isMatch = Bun.password.verifySync(password, hash);\n// => true\n`\n is a collection of utilities for _non-cryptographic_ hashing. Non-cryptographic hashing algorithms are optimized for speed of computation over collision-resistance or security.\nThe standard  functions uses Wyhash to generate a 64-bit hash from an input of arbitrary size.\n`ts\nBun.hash(\"some data here\");\n// 11562320457524636935n\n`\nThe input can be a string, , , , or .\n`ts\nconst arr = new Uint8Array([1, 2, 3, 4]);\nBun.hash(\"some data here\");\nBun.hash(arr);\nBun.hash(arr.buffer);\nBun.hash(new DataView(arr.buffer));\n`\nOptionally, an integer seed can be specified as the second parameter. For 64-bit hashes seeds above  should be given as BigInt to avoid loss of precision.\n`ts\nBun.hash(\"some data here\", 1234);\n// 15724820720172937558n\n`\nAdditional hashing algorithms are available as properties on . The API is the same for each, only changing the return type from number for 32-bit hashes to bigint for 64-bit hashes.\n`ts\nBun.hash.wyhash(\"data\", 1234); // equivalent to Bun.hash()\nBun.hash.crc32(\"data\", 1234);\nBun.hash.adler32(\"data\", 1234);\nBun.hash.cityHash32(\"data\", 1234);\nBun.hash.cityHash64(\"data\", 1234);\nBun.hash.murmur32v3(\"data\", 1234);\nBun.hash.murmur32v2(\"data\", 1234);\nBun.hash.murmur64v2(\"data\", 1234);\n`\n is a general-purpose utility class that lets you incrementally compute a hash of string or binary data using a range of cryptographic hash algorithms. The following algorithms are supported:\n`ts\nconst hasher = new Bun.CryptoHasher(\"sha256\");\nhasher.update(\"hello world\");\nhasher.digest();\n// Uint8Array(32) [ <byte>, <byte>, ... ]\n`\nOnce initialized, data can be incrementally fed to to the hasher using . This method accepts , , and .\n`ts\nconst hasher = new Bun.CryptoHasher();\nhasher.update(\"hello world\");\nhasher.update(new Uint8Array([1, 2, 3]));\nhasher.update(new ArrayBuffer(10));\n`\nIf a  is passed, an optional second parameter can be used to specify the encoding (default ). The following encodings are supported:\n{% table %}\n---\nBinary encodings\n   \n---\nCharacter encodings\n   \n---\nLegacy character encodings\n   \n{% /table %}\n`ts\nhasher.update(\"hello world\"); // defaults to utf8\nhasher.update(\"hello world\", \"hex\");\nhasher.update(\"hello world\", \"base64\");\nhasher.update(\"hello world\", \"latin1\");\n`\nAfter the data has been feed into the hasher, a final hash can be computed using . By default, this method returns a  containing the hash.\n`ts\nconst hasher = new Bun.CryptoHasher();\nhasher.update(\"hello world\");\nhasher.digest();\n// => Uint8Array(32) [ 185, 77, 39, 185, 147, ... ]\n`\nThe  method can optionally return the hash as a string. To do so, specify an encoding:\n`ts\nhasher.digest(\"base64\");\n// => \"uU0nuZNNPgilLlLX2n2r+sSE7+N6U4DukIj3rOLvzek=\"\nhasher.digest(\"hex\");\n// => \"b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\"\n`\nAlternatively, the method can write the hash into a pre-existing  instance. This may be desirable in some performance-sensitive applications.\n`ts\nconst arr = new Uint8Array(32);\nhasher.digest(arr);\nconsole.log(arr);\n// => Uint8Array(32) [ 185, 77, 39, 185, 147, ... ]\n`\n<!-- Bun.sha; -->"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/html-rewriter.md"}, {"role": "assistant", "content": "Bun provides a fast native implementation of the  pattern developed by Cloudflare. It provides a convenient, -like API for traversing and transforming HTML documents.\n`ts\nconst rewriter = new HTMLRewriter();\nrewriter.on(\"\", {\n  element(el) {\n    console.log(el.tagName); // \"body\" | \"div\" | ...\n  },\n});\n`\nTo parse and/or transform the HTML:\n`ts#rewriter.ts\nrewriter.transform(\n  new Response(`\n<!DOCTYPE html>\n<html>\n<!-- comment -->\n<head>\n  <title>My First HTML Page</title>\n</head>\n<body>\n  <h1>My First Heading</h1>\n  <p>My first paragraph.</p>\n</body>\n`));\n`\nView the full documentation on the Cloudflare website."}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/http.md"}, {"role": "assistant", "content": "The page primarily documents the Bun-native  API. Bun also implements  and the Node.js  and  modules.\n{% callout %}\nThese modules have been re-implemented to use Bun's fast internal HTTP infrastructure. Feel free to use these modules directly; frameworks like Express that depend on these modules should work out of the box. For granular compatibility information, see Runtime > Node.js APIs.\n{% /callout %}\nTo start a high-performance HTTP server with a clean API, the recommended approach is .\nStart an HTTP server in Bun with .\n`ts\nBun.serve({\n  fetch(req) {\n    return new Response();\n  },\n});\n`\nThe  handler handles incoming requests. It receives a  object and returns a  or .\n`ts\nBun.serve({\n  fetch(req) {\n    const url = new URL(req.url);\n    if (url.pathname === \"/\") return new Response();\n    if (url.pathname === \"/blog\") return new Response(\"Blog!\");\n    return new Response();\n  },\n});\n`\nTo configure which port and hostname the server will listen on:\n`ts\nBun.serve({\n  port: 8080, // defaults to $BUN_PORT, $PORT, $NODE_PORT otherwise 3000\n  hostname: \"mydomain.com\", // defaults to \"0.0.0.0\"\n  fetch(req) {\n    return new Response();\n  },\n});\n`\nTo listen on a unix domain socket:\n`ts\nBun.serve({\n  unix: \"/tmp/my-socket.sock\", // path to socket\n  fetch(req) {\n    return new Response();\n  },\n});\n`\nError handling\nTo activate development mode, set . By default, development mode is _enabled_ unless  is .\n`ts\nBun.serve({\n  development: true,\n  fetch(req) {\n    throw new Error(\"woops!\");\n  },\n});\n`\nIn development mode, Bun will surface errors in-browser with a built-in error page.\n{% image src=\"/images/exception_page.png\" caption=\"Bun's built-in 500 page\" /%}\nTo handle server-side errors, implement an  handler. This function should return a  to served to the client when an error occurs. This response will supercede Bun's default error page in  mode.\n`ts\nBun.serve({\n  fetch(req) {\n    throw new Error(\"woops!\");\n  },\n  error(error) {\n    return new Response(, {\n      headers: {\n        \"Content-Type\": \"text/html\",\n      },\n    });\n  },\n});\n`\n{% callout %}\nLearn more about debugging in Bun\n{% /callout %}\nThe call to  returns a  object. To stop the server, call the  method.\n`ts\nconst server = Bun.serve({\n  fetch() {\n    return new Response(\"Bun!\");\n  },\n});\nserver.stop();\n`\nTLS\nBun supports TLS out of the box, powered by BoringSSL. Enable TLS by passing in a value for  and ; both are required to enable TLS.\n`ts-diff\n  Bun.serve({\n    fetch(req) {\n      return new Response(\"Hello!!!\");\n    },\n+   tls: {\n+     key: Bun.file(\"./key.pem\"),\n+     cert: Bun.file(\"./cert.pem\"),\n+   }\n  });\n`\nThe  and  fields expect the _contents_ of your TLS key and certificate, _not a path to it_. This can be a string, , , or .\n`ts\nBun.serve({\n  fetch() {},\n  tls: {\n    // BunFile\n    key: Bun.file(\"./key.pem\"),\n    // Buffer\n    key: fs.readFileSync(\"./key.pem\"),\n    // string\n    key: fs.readFileSync(\"./key.pem\", \"utf8\"),\n    // array of above\n    key: [Bun.file(\"./key1.pem\"), Bun.file(\"./key2.pem\")],\n  },\n});\n`\n{% callout %}\nNote \u2014\u00a0Earlier versions of Bun supported passing a file path as  and ; this has been deprecated as of .\n{% /callout %}\nIf your private key is encrypted with a passphrase, provide a value for  to decrypt it.\n`ts-diff\n  Bun.serve({\n    fetch(req) {\n      return new Response(\"Hello!!!\");\n    },\n    tls: {\n      key: Bun.file(\"./key.pem\"),\n      cert: Bun.file(\"./cert.pem\"),\n+     passphrase: \"my-secret-passphrase\",\n    }\n  });\n`\nOptionally, you can override the trusted CA certificates by passing a value for . By default, the server will trust the list of well-known CAs curated by Mozilla. When  is specified, the Mozilla list is overwritten.\n`ts-diff\n  Bun.serve({\n    fetch(req) {\n      return new Response(\"Hello!!!\");\n    },\n    tls: {\n      key: Bun.file(\"./key.pem\"), // path to TLS key\n      cert: Bun.file(\"./cert.pem\"), // path to TLS cert\n+     ca: Bun.file(\"./ca.pem\"), // path to root CA certificate\n    }\n  });\n`\nTo override Diffie-Helman parameters:\n`ts\nBun.serve({\n  // ...\n  tls: {\n    // other config\n    dhParamsFile: \"/path/to/dhparams.pem\", // path to Diffie Helman parameters\n  },\n});\n`\nObject syntax\nThus far, the examples on this page have used the explicit  API. Bun also supports an alternate syntax.\n`ts#server.ts\nimport {type Serve} from \"bun\";\nexport default {\n  fetch(req) {\n    return new Response();\n  },\n} satisfies Serve;\n`\nInstead of passing the server options into ,  it. This file can be executed as-is; when Bun sees a file with a  export containing a  handler, it passes it into  under the hood.\n<!-- This syntax has one major advantage: it is hot-reloadable out of the box. When any source file is changed, Bun will reload the server with the updated code _without restarting the process_. This makes hot reloads nearly instantaneous. Use the  flag when starting the server to enable hot reloading. -->\n<!-- `bash\n$ bun --hot server.ts\n` -->\n<!-- It's possible to configure hot reloading while using the explicit  API; for details refer to Runtime > Hot reloading. -->\nStreaming files\nTo stream a file, return a  object with a  object as the body.\n`ts\nimport { serve, file } from \"bun\";\nserve({\n  fetch(req) {\n    return new Response(Bun.file(\"./hello.txt\"));\n  },\n});\n`\n{% callout %}\n\u26a1\ufe0f Speed \u2014 Bun automatically uses the  system call when possible, enabling zero-copy file transfers in the kernel\u2014the fastest way to send files.\n{% /callout %}\nv0.3.0+] You can send part of a file using the [ method on the  object. This automatically sets the  and  headers on the  object.\n`ts\nBun.serve({\n  fetch(req) {\n    // parse  header\n    const [start = 0, end = Infinity] = req.headers\n      .get(\"Range\") // Range: bytes=0-100\n      .split(\"=\") // [\"Range: bytes\", \"0-100\"]\n      .at(-1) // \"0-100\"\n      .split(\"-\") // [\"0\", \"100\"]\n      .map(Number); // [0, 100]\n    // return a slice of the file\n    const bigFile = Bun.file(\"./big-video.mp4\");\n    return new Response(bigFile.slice(start, end));\n  },\n});\n`\nBenchmarks\nBelow are Bun and Node.js implementations of a simple HTTP server that responds  to each incoming .\n{% codetabs %}\n`ts#Bun\nBun.serve({\n  fetch(req: Request) {\n    return new Response();\n  },\n  port: 3000,\n});\n`\n`ts#Node\nrequire(\"http\")\n  .createServer((req, res) => res.end(\"Bun!\"))\n  .listen(8080);\n`\n{% /codetabs %}\nThe  server can handle roughly 2.5x more requests per second than Node.js on Linux.\n{% table %}\nRuntime\nRequests per second\n---\nNode 16\n~64,000\n---\nBun\n~160,000\n{% /table %}\n{% image width=\"499\" alt=\"image\" src=\"https://user-images.githubusercontent.com/709451/162389032-fc302444-9d03-46be-ba87-c12bd8ce89a0.png\" /%}\nReference\n{% details summary=\"See TypeScript definitions\" %}\n`ts\ninterface Bun {\n  serve(options: {\n    fetch: (req: Request, server: Server) => Response | Promise<Response>;\n    hostname?: string;\n    port?: number;\n    development?: boolean;\n    error?: (error: Error) => Response | Promise<Response>;\n    tls?: {\n      key?:\n        | string\n        | TypedArray\n        | BunFile\n        | Array<string | TypedArray | BunFile>;\n      cert?:\n        | string\n        | TypedArray\n        | BunFile\n        | Array<string | TypedArray | BunFile>;\n      ca?: string | TypedArray | BunFile | Array<string | TypedArray | BunFile>;\n      passphrase?: string;\n      dhParamsFile?: string;\n    };\n    maxRequestBodySize?: number;\n    lowMemoryMode?: boolean;\n  }): Server;\n}\ninterface Server {\n  development: boolean;\n  hostname: string;\n  port: number;\n  pendingRequests: number;\n  stop(): void;\n}\n`\n{% /details %}"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/import-meta.md"}, {"role": "assistant", "content": "The  object is a way for a module to access information about itself. It's part of the JavaScript language, but its contents are not standardized. Each \"host\" (browser, runtime, etc) is free to implement any properties it wishes on the  object.\nBun implements the following properties.\n`ts#/path/to/project/file.ts\nimport.meta.dir;   // => \"/path/to/project\"\nimport.meta.file;  // => \"file.ts\"\nimport.meta.path;  // => \"/path/to/project/file.ts\"\nimport.meta.main;  //  if this file is directly executed by \n                   //  otherwise\nimport.meta.resolveSync(\"zod\")\n// resolve an import specifier relative to the directory\n`\n{% table %}\n---\nAbsolute path to the directory containing the current file, e.g. . Equivalent to  in CommonJS modules (and Node.js)\n---\nThe name of the current file, e.g. \n---\nAbsolute path to the current file, e.g. . Equivalent to  in CommonJS modules (and Node.js)\n---\n Indicates whether the current file is the entrypoint to the current  process. Is the file being directly executed by  or is it being imported?\n---\nResolve a module specifier (e.g.  or ) to an absolute path. While file would be imported if the specifier were imported from this file?\n  `ts\n  import.meta.resolveSync(\"zod\");\n  // => \"/path/to/project/node_modules/zod/index.ts\"\n  import.meta.resolveSync(\"./file.tsx\");\n  // => \"/path/to/project/file.tsx\"\n  `\n{% /table %}"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/node-api.md"}, {"role": "assistant", "content": "Node-API is an interface for building native add-ons to Node.js. Bun implements 95% of this interface from scratch, so most existing Node-API extensions will work with Bun out of the box. Track the completion status of it in this issue.\nAs in Node.js,  files (Node-API modules) can be required directly in Bun.\n`js\nconst napi = require(\"./my-node-module.node\");\n`\nAlternatively, use :\n`js\nlet mod = { exports: {} };\nprocess.dlopen(mod, \"./my-node-module.node\");\n`\nBun polyfills the  package, which is used by many Node-API modules to detect which  binding to ."}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/spawn.md"}, {"role": "assistant", "content": "Spawn child processes with  or .\nSpawn a process ()\nProvide a command as an array of strings. The result of  is a  object.\n`ts\nBun.spawn([\"echo\", \"hello\"]);\n`\nThe second argument to  is a parameters object that can be used to configure the subprocess.\n`ts\nconst proc = Bun.spawn([\"echo\", \"hello\"], {\n  cwd: \"./path/to/subdir\", // specify a working directory\n  env: { ...process.env, FOO: \"bar\" }, // specify environment variables\n  onExit(proc, exitCode, signalCode, error) {\n    // exit handler\n  },\n});\nproc.pid; // process ID of subprocess\n`\nInput stream\nBy default, the input stream of the subprocess is undefined; it can be configured with the  parameter.\n`ts\nconst proc = Bun.spawn([\"cat\"], {\n  stdin: await fetch(\"https://raw.githubusercontent.com/oven-sh/bun/main/examples/hashing.js\"),\n});\nconst text = await new Response(proc.stdout).text();\nconsole.log(text); // \"const input = \"hello world\".repeat(400); ...\"\n`\n{% table %}\n---\nDefault. Provide no input to the subprocess\n---\nReturn a  for fast incremental writing\n---\nInherit the  of the parent process\n---\nRead from the specified file.\n---\nUse a binary buffer as input.\n---\nUse the response  as input.\n---\nUse the request  as input.\n---\nRead from the file with a given file descriptor.\n{% /table %}\nThe  option lets incrementally write to the subprocess's input stream from the parent process.\n`ts\nconst proc = Bun.spawn([\"cat\"], {\n  stdin: \"pipe\", // return a FileSink for writing\n});\n// enqueue string data\nproc.stdin.write(\"hello\");\n// enqueue binary data\nconst enc = new TextEncoder();\nproc.stdin.write(enc.encode(\" world!\"));\n// send buffered data\nproc.stdin.flush();\n// close the input stream\nproc.stdin.end();\n`\nOutput streams\nYou can read results from the subprocess via the  and  properties. By default these are instances of .\n`ts\nconst proc = Bun.spawn([\"echo\", \"hello\"]);\nconst text = await new Response(proc.stdout).text();\nconsole.log(text); // => \"hello\"\n`\nConfigure the output stream by passing one of the following values to :\n{% table %}\n---\nDefault for . Pipe the output to a  on the returned  object.\n---\nDefault for . Inherit from the parent process.\n---\nWrite to the specified file.\n---\nWrite to .\n---\nWrite to the file with the given file descriptor.\n{% /table %}\nExit handling\nUse the  callback to listen for the process exiting or being killed.\n`ts\nconst proc = Bun.spawn([\"echo\", \"hello\"], {\n  onExit(proc, exitCode, signalCode, error) {\n    // exit handler\n  },\n});\n`\nFor convenience, the  property is a  that resolves when the process exits.\n`ts\nconst proc = Bun.spawn([\"echo\", \"hello\"]);\nawait proc.exited; // resolves when process exit\nproc.killed; // boolean \u2014 was the process killed?\nproc.exitCode; // null | number\nproc.signalCode; // null | \"SIGABRT\" | \"SIGALRM\" | ...\n`\nTo kill a process:\n`ts\nconst proc = Bun.spawn([\"echo\", \"hello\"]);\nproc.kill();\nproc.killed; // true\nproc.kill(); // specify an exit code\n`\nThe parent  process will not terminate until all child processes have exited. Use  to detach the child process from the parent.\n`\nconst proc = Bun.spawn([\"echo\", \"hello\"]);\nproc.unref();\n`\nBlocking API ()\nBun provides a synchronous equivalent of  called . This is a blocking API that supports the same inputs and parameters as . It returns a  object, which differs from  in a few ways.\nIt contains a  property that indicates whether the process exited with a zero exit code.\nThe  and  properties are instances of  instead of .\nThere is no  property. Use  to incrementally write to the subprocess's input stream.\n`ts\nconst proc = Bun.spawnSync([\"echo\", \"hello\"]);\nconsole.log(proc.stdout.toString());\n// => \"hello\\n\"\n`\nAs a rule of thumb, the asynchronous  API is better for HTTP servers and apps, and  is better for building command-line tools.\nBenchmarks\n{%callout%}\n\u26a1\ufe0f Under the hood,  and  use .\n{%/callout%}\nBun's  spawns processes 60% faster than the Node.js  module.\n`bash\n$ bun spawn.mjs\ncpu: Apple M1 Max\nruntime: bun 0.2.0 (arm64-darwin)\nbenchmark              time (avg)             (min \u2026 max)       p75       p99      p995\n--------------------------------------------------------- -----------------------------\nspawnSync echo hi  888.14 \u00b5s/iter    (821.83 \u00b5s \u2026 1.2 ms) 905.92 \u00b5s      1 ms   1.03 ms\n$ node spawn.node.mjs\ncpu: Apple M1 Max\nruntime: node v18.9.1 (arm64-darwin)\nbenchmark              time (avg)             (min \u2026 max)       p75       p99      p995\n--------------------------------------------------------- -----------------------------\nspawnSync echo hi    1.47 ms/iter     (1.14 ms \u2026 2.64 ms)   1.57 ms   2.37 ms   2.52 ms\n`\nReference\nA simple reference of the Spawn API and types are shown below. The real types have complex generics to strongly type the  streams with the options passed to  and . For full details, find these types as defined bun.d.ts.\n`ts\ninterface Bun {\n  spawn(command: string[], options?: SpawnOptions.OptionsObject): Subprocess;\n  spawnSync(command: string[], options?: SpawnOptions.OptionsObject): SyncSubprocess;\n  spawn(options: { cmd: string[] } & SpawnOptions.OptionsObject): Subprocess;\n  spawnSync(options: { cmd: string[] } & SpawnOptions.OptionsObject): SyncSubprocess;\n}\nnamespace SpawnOptions {\n  interface OptionsObject {\n    cwd?: string;\n    env?: Record<string, string>;\n    stdin?: SpawnOptions.Readable;\n    stdout?: SpawnOptions.Writable;\n    stderr?: SpawnOptions.Writable;\n    onExit?: (proc: Subprocess, exitCode: number | null, signalCode: string | null, error: Error | null) => void;\n  }\n  type Readable =\n    | \"pipe\"\n    | \"inherit\"\n    | \"ignore\"\n    | null // equivalent to \"ignore\"\n    | undefined // to use default\n    | BunFile\n    | ArrayBufferView\n    | number;\n  type Writable =\n    | \"pipe\"\n    | \"inherit\"\n    | \"ignore\"\n    | null // equivalent to \"ignore\"\n    | undefined // to use default\n    | BunFile\n    | ArrayBufferView\n    | number\n    | ReadableStream\n    | Blob\n    | Response\n    | Request;\n}\ninterface Subprocess<Stdin, Stdout, Stderr> {\n  readonly pid: number;\n  // the exact stream types here are derived from the generic parameters\n  readonly stdin: number | ReadableStream | FileSink | undefined;\n  readonly stdout: number | ReadableStream | undefined;\n  readonly stderr: number | ReadableStream | undefined;\n  readonly exited: Promise<number>;\n  readonly exitCode: number | undefined;\n  readonly signalCode: Signal | null;\n  readonly killed: boolean;\n  ref(): void;\n  unref(): void;\n  kill(code?: number): void;\n}\ninterface SyncSubprocess<Stdout, Stderr> {\n  readonly pid: number;\n  readonly success: boolean;\n  // the exact buffer types here are derived from the generic parameters\n  readonly stdout: Buffer | undefined;\n  readonly stderr: Buffer | undefined;\n}\ntype ReadableSubprocess = Subprocess<any, \"pipe\", \"pipe\">;\ntype WritableSubprocess = Subprocess<\"pipe\", any, any>;\ntype PipedSubprocess = Subprocess<\"pipe\", \"pipe\", \"pipe\">;\ntype NullSubprocess = Subprocess<null, null, null>;\ntype ReadableSyncSubprocess = SyncSubprocess<\"pipe\", \"pipe\">;\ntype NullSyncSubprocess = SyncSubprocess<null, null>;\ntype Signal =\n  | \"SIGABRT\"\n  | \"SIGALRM\"\n  | \"SIGBUS\"\n  | \"SIGCHLD\"\n  | \"SIGCONT\"\n  | \"SIGFPE\"\n  | \"SIGHUP\"\n  | \"SIGILL\"\n  | \"SIGINT\"\n  | \"SIGIO\"\n  | \"SIGIOT\"\n  | \"SIGKILL\"\n  | \"SIGPIPE\"\n  | \"SIGPOLL\"\n  | \"SIGPROF\"\n  | \"SIGPWR\"\n  | \"SIGQUIT\"\n  | \"SIGSEGV\"\n  | \"SIGSTKFLT\"\n  | \"SIGSTOP\"\n  | \"SIGSYS\"\n  | \"SIGTERM\"\n  | \"SIGTRAP\"\n  | \"SIGTSTP\"\n  | \"SIGTTIN\"\n  | \"SIGTTOU\"\n  | \"SIGUNUSED\"\n  | \"SIGURG\"\n  | \"SIGUSR1\"\n  | \"SIGUSR2\"\n  | \"SIGVTALRM\"\n  | \"SIGWINCH\"\n  | \"SIGXCPU\"\n  | \"SIGXFSZ\"\n  | \"SIGBREAK\"\n  | \"SIGLOST\"\n  | \"SIGINFO\";\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/sqlite.md"}, {"role": "assistant", "content": "Bun natively implements a high-performance SQLite3 driver. To use it import from the built-in  module.\n`ts\nimport { Database } from \"bun:sqlite\";\nconst db = new Database(\":memory:\");\nconst query = db.query(\"select 'Hello world' as message;\");\nquery.get(); // => { message: \"Hello world\" }\n`\nThe API is simple, synchronous, and fast. Credit to better-sqlite3 and its contributors for inspiring the API of .\nFeatures include:\nTransactions\nParameters (named & positional)\nPrepared statements\nDatatype conversions ( becomes )\nThe fastest performance of any SQLite driver for JavaScript\nThe  module is roughly 3-6x faster than  and 8-9x faster than  for read queries. Each driver was benchmarked against the Northwind Traders dataset. View and run the benchmark source.\n{% image width=\"738\" alt=\"SQLite benchmarks for Bun, better-sqlite3, and deno.land/x/sqlite\" src=\"https://user-images.githubusercontent.com/709451/168459263-8cd51ca3-a924-41e9-908d-cf3478a3b7f3.png\" caption=\"Benchmarked on an M1 MacBook Pro (64GB) running macOS 12.3.1\" /%}\nDatabase\nTo open or create a SQLite3 database:\n`ts\nimport { Database } from \"bun:sqlite\";\nconst db = new Database(\"mydb.sqlite\");\n`\nTo open an in-memory database:\n`ts\nimport { Database } from \"bun:sqlite\";\n// all of these do the same thing\nconst db = new Database(\":memory:\");\nconst db = new Database();\nconst db = new Database(\"\");\n`\nTo open in  mode:\n`ts\nimport { Database } from \"bun:sqlite\";\nconst db = new Database(\"mydb.sqlite\", { readonly: true });\n`\nTo create the database if the file doesn't exist:\n`ts\nimport { Database } from \"bun:sqlite\";\nconst db = new Database(\"mydb.sqlite\", { create: true });\n`\nTo close a database:\n`ts\nconst db = new Database();\ndb.close();\n`\nNote:  is called automatically when the database is garbage collected. It is safe to call multiple times but has no effect after the first.\n supports SQLite's built-in mechanism for serializing and deserializing databases to and from memory.\n`ts\nconst olddb = new Database(\"mydb.sqlite\");\nconst contents = olddb.serialize(); // => Uint8Array\nconst newdb = Database.deserialize(contents);\n`\nInternally,  calls .\nUse the  method on your  instance to prepare a SQL query. The result is a  instance that will be cached on the  instance. _The query will not be executed._\n`ts\nconst query = db.query();\n`\n{% callout %}\nNote \u2014 Use the  method to prepare a query _without_ caching it on the  instance.\n`ts\n// compile the prepared statement\nconst query = db.prepare(\"SELECT  FROM foo WHERE bar = ?\");\n`\n{% /callout %}\nStatements\nA  is a _prepared query_, which means it's been parsed and compiled into an efficient binary form. It can be executed multiple times in a performant way.\nCreate a statement with the  method on your  instance.\n`ts\nconst query = db.query();\n`\nQueries can contain parameters. These can be numerical () or named ( or  or ).\n`ts\nconst query = db.query();\nconst query = db.query();\n`\nValues are bound to these parameters when the query is executed. A  can be executed with several different methods, each returning the results in a different form.\nUse  to run a query and get back the results as an array of objects.\n`ts\nconst query = db.query();\nquery.all({ $message: \"Hello world\" });\n// => [{ message: \"Hello world\" }]\n`\nInternally, this calls  and repeatedly calls  until it returns .\nUse  to run a query and get back the first result as an object.\n`ts\nconst query = db.query();\nquery.get({ $message: \"Hello world\" });\n// => { $message: \"Hello world\" }\n`\nInternally, this calls  followed by  until it no longer returns . If the query returns no rows,  is returned.\nUse  to run a query and get back . This is useful for queries schema-modifying queries (e.g. ) or bulk write operations.\n`ts\nconst query = db.query();\nquery.run();\n// => undefined\n`\nInternally, this calls  and calls  once. Stepping through all the rows is not necessary when you don't care about the results.\nUse  to run a query and get back all results as an array of arrays.\n`ts\nconst query = db.query();\nquery.values({ $message: \"Hello world\" });\nquery.values(2);\n// [\n//   [ \"Iron Man\", 2008 ],\n//   [ \"The Avengers\", 2012 ],\n//   [ \"Ant-Man: Quantumania\", 2023 ],\n// ]\n`\nInternally, this calls  and repeatedly calls  until it returns .\nUse  to destroy a  and free any resources associated with it. Once finalized, a  cannot be executed again. Typically, the garbage collector will do this for you, but explicit finalization may be useful in performance-sensitive applications.\n`ts\nconst query = db.query(\"SELECT title, year FROM movies\");\nconst movies = query.all();\nquery.finalize();\n`\nCalling  on a  instance prints the expanded SQL query. This is useful for debugging.\n`ts\nimport { Database } from \"bun:sqlite\";\n// setup\nconst query = db.query(\"SELECT $param;\");\nconsole.log(query.toString()); // => \"SELECT NULL\"\nquery.run(42);\nconsole.log(query.toString()); // => \"SELECT 42\"\nquery.run(365);\nconsole.log(query.toString()); // => \"SELECT 365\"\n`\nInternally, this calls . The parameters are expanded using the most recently bound values.\nParameters\nQueries can contain parameters. These can be numerical () or named ( or  or ). Bind values to these parameters when executing the query:\n{% codetabs %}\n`ts#Query\nconst query = db.query(\"SELECT  FROM foo WHERE bar = $bar\");\nconst results = query.all({\n  $bar: \"bar\",\n});\n`\n`json#Results\n[\n  { \"$bar\": \"bar\" }\n]\n`\n{% /codetabs %}\nNumbered (positional) parameters work too:\n{% codetabs %}\n`ts#Query\nconst query = db.query(\"SELECT ?1, ?2\");\nconst results = query.all(\"hello\", \"goodbye\");\n`\n`ts#Results\n[\n  {\n    \"?1\": \"hello\",\n    \"?2\": \"goodbye\"\n  }\n]\n`\n{% /codetabs %}\nTransactions\nTransactions are a mechanism for executing multiple queries in an _atomic_ way; that is, either all of the queries succeed or none of them do. Create a transaction with the  method:\n`ts\nconst insertCat = db.prepare(\"INSERT INTO cats (name) VALUES ($name)\");\nconst insertCats = db.transaction(cats => {\n  for (const cat of cats) insertCat.run(cat);\n});\n`\nAt this stage, we haven't inserted any cats! The call to  returns a new function () that _wraps_ the function that executes the queries.\nTo execute the transaction, call this function. All arguments will be passed through to the wrapped function; the return value of the wrapped function will be returned by the transaction function. The wrapped function also has access to the  context as defined where the transaction is executed.\n`ts\nconst insert = db.prepare(\"INSERT INTO cats (name) VALUES ($name)\");\nconst insertCats = db.transaction(cats => {\n  for (const cat of cats) insert.run(cat);\n  return cats.length;\n});\nconst count = insertCats([\n  { $name: \"Keanu\" },\n  { $name: \"Salem\" },\n  { $name: \"Crookshanks\" },\n]);\nconsole.log();\n`\nThe driver will automatically  a transaction when  is called and  it when the wrapped function returns. If an exception is thrown, the transaction will be rolled back. The exception will propagate as usual; it is not caught.\n{% callout %}\nNested transactions \u2014 Transaction functions can be called from inside other transaction functions. When doing so, the inner transaction becomes a savepoint.\n{% details summary=\"View nested transaction example\" %}\n`ts\n// setup\nimport { Database } from \"bun:sqlite\";\nconst db = Database.open(\":memory:\");\ndb.run(\n  \"CREATE TABLE expenses (id INTEGER PRIMARY KEY AUTOINCREMENT, note TEXT, dollars INTEGER);\",\n);\ndb.run(\n  \"CREATE TABLE cats (id INTEGER PRIMARY KEY AUTOINCREMENT, name TEXT UNIQUE, age INTEGER)\",\n);\nconst insertExpense = db.prepare(\n  \"INSERT INTO expenses (note, dollars) VALUES (?, ?)\",\n);\nconst insert = db.prepare(\"INSERT INTO cats (name, age) VALUES ($name, $age)\");\nconst insertCats = db.transaction(cats => {\n  for (const cat of cats) insert.run(cat);\n});\nconst adopt = db.transaction(cats => {\n  insertExpense.run(\"adoption fees\", 20);\n  insertCats(cats); // nested transaction\n});\nadopt([\n  { $name: \"Joey\", $age: 2 },\n  { $name: \"Sally\", $age: 4 },\n  { $name: \"Junior\", $age: 1 },\n]);\n`\n{% /details %}\n{% /callout %}\nTransactions also come with , , and  versions.\n`ts\ninsertCats(cats); // uses \"BEGIN\"\ninsertCats.deferred(cats); // uses \"BEGIN DEFERRED\"\ninsertCats.immediate(cats); // uses \"BEGIN IMMEDIATE\"\ninsertCats.exclusive(cats); // uses \"BEGIN EXCLUSIVE\"\n`\nTo load a SQLite extension, call  on your  instance\n`ts\nimport { Database } from \"bun:sqlite\";\nconst db = new Database();\ndb.loadExtension(\"myext\");\n`\n{% details summary=\"For macOS users\" %}\nMacOS users By default, macOS ships with Apple's proprietary build of SQLite, which doesn't support extensions. To use extensions, you'll need to install a vanilla build of SQLite.\n`bash\n$ brew install sqlite\n$ which sqlite get path to binary\n`\nTo point  to the new build, call  before creating any  instances. (On other operating systems, this is a no-op.) Pass a path to the SQLite  file, _not_ the executable. With recent versions of Homebrew this is something like .\n`ts\nimport { Database } from \"bun:sqlite\";\nDatabase.setCustomSQLite(\"/path/to/libsqlite.dylib\");\nconst db = new Database();\ndb.loadExtension(\"myext\");\n`\n{% /details %}\nReference\n`ts\nclass Database {\n  constructor(\n    filename: string,\n    options?:\n      | number\n      | {\n          readonly?: boolean;\n          create?: boolean;\n          readwrite?: boolean;\n        },\n  );\n  query<Params, ReturnType>(sql: string): Statement<Params, ReturnType>;\n}\nclass Statement<Params, ReturnType> {\n  all(params: Params): ReturnType[];\n  get(params: Params): ReturnType | undefined;\n  run(params: Params): void;\n  values(params: Params): unknown[][];\n  finalize(): void; // destroy statement and clean up resources\n  toString(): string; // serialize to SQL\n  columnNames: string[]; // the column names of the result set\n  paramsCount: number; // the number of parameters expected by the statement\n  native: any; // the native object representing the statement\n}\ntype SQLQueryBindings =\n  | string\n  | bigint\n  | TypedArray\n  | number\n  | boolean\n  | null\n  | Record<string, string | bigint | TypedArray | number | boolean | null>;\n`\nDatatypes\n| JavaScript type | SQLite type            |\n| --------------- | ---------------------- |\n|         |                  |\n|         |  or  |\n|        |  (1 or 0)     |\n|     |                  |\n|         |                  |\n|         |               |\n|           |                  |"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/streams.md"}, {"role": "assistant", "content": "Streams are an important abstraction for working with binary data without loading it all into memory at once. They are commonly used for reading and writing files, sending and receiving network requests, and processing large amounts of data.\nBun implements the Web APIs  and .\n{% callout %}\nBun also implements the  module, including , , and . For complete documentation, refer to the Node.js docs.\n{% /callout %}\nTo create a simple :\n`ts\nconst stream = new ReadableStream({\n  start(controller) {\n    controller.enqueue(\"hello\");\n    controller.enqueue(\"world\");\n    controller.close();\n  },\n});\n`\nThe contents of a  can be read chunk-by-chunk with  syntax.\n`ts\nfor await (const chunk of stream) {\n  console.log(chunk);\n  // => \"hello\"\n  // => \"world\"\n}\n`\nDirect \nBun implements an optimized version of  that avoid unnecessary data copying & queue management logic. With a traditional , chunks of data are _enqueued_. Each chunk is copied into a queue, where it sits until the stream is ready to send more data.\n`ts\nconst stream = new ReadableStream({\n  start(controller) {\n    controller.enqueue(\"hello\");\n    controller.enqueue(\"world\");\n    controller.close();\n  },\n});\n`\nWith a direct , chunks of data are written directly to the stream. No queueing happens, and there's no need to clone the chunk data into memory. The  API is updated to reflect this; instead of  you call .\n`ts\nconst stream = new ReadableStream({\n  type: \"direct\",\n  pull(controller) {\n    controller.write(\"hello\");\n    controller.write(\"world\");\n  },\n});\n`\nWhen using a direct , all chunk queueing is handled by the destination. The consumer of the stream receives exactly what is passed to , without any encoding or modification.\nThe  class is a fast incremental writer for constructing an  of unknown size.\n`ts\nconst sink = new Bun.ArrayBufferSink();\nsink.write(\"h\");\nsink.write(\"e\");\nsink.write(\"l\");\nsink.write(\"l\");\nsink.write(\"o\");\nsink.end();\n// ArrayBuffer(5) [ 104, 101, 108, 108, 111 ]\n`\nTo instead retrieve the data as a , pass the  option to the constructor.\n`ts-diff\nconst sink = new Bun.ArrayBufferSink({\n+ asUint8Array: true\n});\nsink.write(\"h\");\nsink.write(\"e\");\nsink.write(\"l\");\nsink.write(\"l\");\nsink.write(\"o\");\nsink.end();\n// Uint8Array(5) [ 104, 101, 108, 108, 111 ]\n`\nThe  method supports strings, typed arrays, , and .\n`ts\nsink.write(\"h\");\nsink.write(new Uint8Array([101, 108]));\nsink.write(Buffer.from(\"lo\").buffer);\nsink.end();\n`\nOnce  is called, no more data can be written to the . However, in the context of buffering a stream, it's useful to continuously write data and periodically  the contents (say, into a ). To support this, pass  to the constructor.\n`ts\nconst sink = new Bun.ArrayBufferSink({\n  stream: true,\n});\nsink.write(\"h\");\nsink.write(\"e\");\nsink.write(\"l\");\nsink.flush();\n// ArrayBuffer(5) [ 104, 101, 108 ]\nsink.write(\"l\");\nsink.write(\"o\");\nsink.flush();\n// ArrayBuffer(5) [ 108, 111 ]\n`\nThe  method returns the buffered data as an  (or  if ) and clears internal buffer.\nTo manually set the size of the internal buffer in bytes, pass a value for :\n`ts\nconst sink = new Bun.ArrayBufferSink({\n  highWaterMark: 1024  1024, // 1 MB\n});\n`\n{% details summary=\"Reference\" %}\n`ts\n/\n  Fast incremental writer that becomes an  on end().\n /\nexport class ArrayBufferSink {\n  constructor();\n  start(options?: {\n    asUint8Array?: boolean;\n    /\n      Preallocate an internal buffer of this size\n      This can significantly improve performance when the chunk size is small\n     /\n    highWaterMark?: number;\n    /\n      On {@link ArrayBufferSink.flush}, return the written data as a .\n      Writes will restart from the beginning of the buffer.\n     /\n    stream?: boolean;\n  }): void;\n  write(\n    chunk: string | ArrayBufferView | ArrayBuffer | SharedArrayBuffer,\n  ): number;\n  /\n    Flush the internal buffer\n   \n    If {@link ArrayBufferSink.start} was passed a  option, this will return a \n    If {@link ArrayBufferSink.start} was passed a  option and , this will return a \n    Otherwise, this will return the number of bytes written since the last flush\n   \n    This API might change later to separate Uint8ArraySink and ArrayBufferSink\n   /\n  flush(): number | Uint8Array | ArrayBuffer;\n  end(): ArrayBuffer | Uint8Array;\n}\n`\n{% /details %}"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/tcp.md"}, {"role": "assistant", "content": "Use Bun's native TCP API to implement performance sensitive systems like database clients, game servers, or anything that needs to communicate over TCP (instead of HTTP). This is a low-level API intended for library authors and for advanced use cases.\nStart a server ()\nTo start a TCP server with :\n`ts\nBun.listen({\n  hostname: \"localhost\",\n  port: 8080,\n  socket: {\n    data(socket, data) {}, // message received from client\n    open(socket) {}, // socket opened\n    close(socket) {}, // socket closed\n    drain(socket) {}, // socket ready for more data\n    error(socket, error) {}, // error handler\n  },\n});\n`\n{% details summary=\"An API designed for speed\" %}\nIn Bun, a set of handlers are declared once per server instead of assigning callbacks to each socket, as with Node.js  or the web-standard  API.\n`ts\nBun.listen({\n  hostname: \"localhost\",\n  port: 8080,\n  socket: {\n    open(socket) {},\n    data(socket, data) {},\n    drain(socket) {},\n    close(socket) {},\n    error(socket, error) {},\n  },\n});\n`\nFor performance-sensitive servers, assigning listeners to each socket can cause significant garbage collector pressure and increase memory usage. By contrast, Bun only allocates one handler function for each event and shares it among all sockets. This is a small optimization, but it adds up.\n{% /details %}\nContextual data can be attached to a socket in the  handler.\n`ts\ntype SocketData = { sessionId: string };\nBun.listen<SocketData>({\n  hostname: \"localhost\",\n  port: 8080,\n  socket: {\n    data(socket, data) {\n      socket.write();\n    },\n    open(socket) {\n      socket.data = { sessionId: \"abcd\" };\n    },\n  },\n});\n`\nTo enable TLS, pass a  object containing  and  fields.\n`ts\nBun.listen({\n  hostname: \"localhost\",\n  port: 8080,\n  socket: {\n    data(socket, data) {},\n  },\n  tls: {\n    // can be string, BunFile, TypedArray, Buffer, or array thereof\n    key: Bun.file(\"./key.pem\"),\n    cert: Bun.file(\"./cert.pem\"),\n  },\n});\n`\n{% callout %}\nNote \u2014\u00a0Earlier versions of Bun supported passing a file path as  and ; this has been deprecated as of .\n{% /callout %}\nThe  and  fields expect the _contents_ of your TLS key and certificate. This can be a string, , , or .\n`ts\nBun.listen({\n  // ...\n  tls: {\n    // BunFile\n    key: Bun.file(\"./key.pem\"),\n    // Buffer\n    key: fs.readFileSync(\"./key.pem\"),\n    // string\n    key: fs.readFileSync(\"./key.pem\", \"utf8\"),\n    // array of above\n    key: [Bun.file('./key1.pem'), Bun.file('./key2.pem')]\n  },\n});\n`\nThe result of  is a server that conforms to the  interface.\n`ts\nconst server = Bun.listen({\n  / config/\n});\n// stop listening\n// parameter determines whether active connections are closed\nserver.stop(true);\n// let Bun process exit even if server is still listening\nserver.unref();\n`\nCreate a connection ()\nUse  to connect to a TCP server. Specify the server to connect to with  and . TCP clients can define the same set of handlers as , plus a couple client-specific handlers.\n`ts\n// The client\nconst socket = Bun.connect({\n  hostname: \"localhost\",\n  port: 8080,\n  socket: {\n    data(socket, data) {},\n    open(socket) {},\n    close(socket) {},\n    drain(socket) {},\n    error(socket, error) {},\n    // client-specific handlers\n    connectError(socket, error) {}, // connection failed\n    end(socket) {}, // connection closed by server\n    timeout(socket) {}, // connection timed out\n  },\n});\n`\nTo require TLS, specify .\n`ts\n// The client\nconst socket = Bun.connect({\n  // ... config\n  tls: true,\n});\n`\nHot reloading\nBoth TCP servers and sockets can be hot reloaded with new handlers.\n{% codetabs %}\n`ts#Server\nconst server = Bun.listen({ / config / })\n// reloads handlers for all active server-side sockets\nserver.reload({\n  socket: {\n    data(){\n      // new 'data' handler\n    }\n  }\n})\n`\n`ts#Client\nconst socket = Bun.connect({ / config / })\nsocket.reload({\n  data(){\n    // new 'data' handler\n  }\n})\n`\n{% /codetabs %}\nBuffering\nCurrently, TCP sockets in Bun do not buffer data. For performance-sensitive code, it's important to consider buffering carefully. For example, this:\n`ts\nsocket.write(\"h\");\nsocket.write(\"e\");\nsocket.write(\"l\");\nsocket.write(\"l\");\nsocket.write(\"o\");\n`\n...performs significantly worse than this:\n`ts\nsocket.write(\"hello\");\n`\nTo simplify this for now, consider using Bun's  with the  option:\n`ts\nconst sink = new ArrayBufferSink({ stream: true, highWaterMark: 1024 });\nsink.write(\"h\");\nsink.write(\"e\");\nsink.write(\"l\");\nsink.write(\"l\");\nsink.write(\"o\");\nqueueMicrotask(() => {\n  var data = sink.flush();\n  if (!socket.write(data)) {\n    // put it back in the sink if the socket is full\n    sink.write(data);\n  }\n});\n`\n{% callout %}\nCorking \u2014 Support for corking is planned, but in the meantime backpressure must be managed manually with the  handler.\n{% /callout %}"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/test.md"}, {"role": "assistant", "content": "See the  documentation."}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/transpiler.md"}, {"role": "assistant", "content": "Bun exposes its internal transpiler via the  class. To create an instance of Bun's transpiler:\n`ts\nconst transpiler = new Bun.Transpiler({\n  loader: \"tsx\", // \"js | \"jsx\" | \"ts\" | \"tsx\"\n});\n`\nTranspile code synchronously with the  method. Modules are not resolved and the code is not executed. The result is a string of vanilla JavaScript code.\n<!-- It is synchronous and runs in the same thread as other JavaScript code. -->\n{% codetabs %}\n`js#Example\nconst transpiler = new Bun.Transpiler({\n  loader: 'tsx',\n});\nconst code = `\nimport  as whatever from \"./whatever.ts\"\nexport function Home(props: {title: string}){\n  return <p>{props.title}</p>;\n}`;\nconst result = transpiler.transformSync(code);\n`\n`js#Result\nimport { __require as require } from \"bun:wrap\";\nimport  as JSX from \"react/jsx-dev-runtime\";\nvar jsx = require(JSX).jsxDEV;\nexport default jsx(\n  \"div\",\n  {\n    children: \"hi!\",\n  },\n  undefined,\n  false,\n  undefined,\n  this,\n);\n`\n{% /codetabs %}\nTo override the default loader specified in the  constructor, pass a second argument to .\n`ts\nawait transpiler.transform(\"<div>hi!</div>\", \"tsx\");\n`\n{% details summary=\"Nitty gritty\" %}\nWhen  is called, the transpiler is run in the same thread as the currently executed code.\nIf a macro is used, it will be run in the same thread as the transpiler, but in a separate event loop from the rest of your application. Currently, globals between macros and regular code are shared, which means it is possible (but not recommended) to share states between macros and regular code. Attempting to use AST nodes outside of a macro is undefined behavior.\n{% /details %}\nThe  method is an async version of  that returns a .\n`js\nconst transpiler = new Bun.Transpiler({ loader: \"jsx\" });\nconst result = await transpiler.transform(\"<div>hi!</div>\");\nconsole.log(result);\n`\nUnless you're transpiling _many_ large files, you should probably use . The cost of the threadpool will often take longer than actually transpiling code.\n`ts\nawait transpiler.transform(\"<div>hi!</div>\", \"tsx\");\n`\n{% details summary=\"Nitty gritty\" %}\nThe  method runs the transpiler in Bun's worker threadpool, so if you run it 100 times, it will run it across  threads, without blocking the main JavaScript thread.\nIf your code uses a macro, it will potentially spawn a new copy of Bun's JavaScript runtime environment in that new thread.\n{% /details %}\nThe  instance can also scan some source code and return a list of its imports and exports, plus additional metadata about each one. Type-only imports and exports are ignored.\n{% codetabs %}\n`ts#Example\nconst transpiler = new Bun.Transpiler({\n  loader: 'tsx',\n});\nconst code = `\nimport React from 'react';\nimport type {ReactNode} from 'react';\nconst val = require('./cjs.js')\nimport('./loader');\nexport const name = \"hello\";\n`;\nconst result = transpiler.scan(code);\n`\n`json#Output\n{\n  \"exports\": [\n    \"name\"\n  ],\n  \"imports\": [\n    {\n      \"kind\": \"import-statement\",\n      \"path\": \"react\"\n    },\n    {\n      \"kind\": \"import-statement\",\n      \"path\": \"remix\"\n    },\n    {\n      \"kind\": \"dynamic-import\",\n      \"path\": \"./loader\"\n    }\n  ]\n}\n`\n{% /codetabs %}\nEach import in the  array has a  and . Bun categories imports into the following kinds:\n: \n: \n: \n: \n: \n: \n<!-- - : \n:  -->\nFor performance-sensitive code, you can use the  method to get a list of imports. It's faster than  (especially for large files) but marginally less accurate due to some performance optimizations.\n{% codetabs %}\n`ts#Example\nconst transpiler = new Bun.Transpiler({\n  loader: 'tsx',\n});\nconst code = `\nimport React from 'react';\nimport type {ReactNode} from 'react';\nconst val = require('./cjs.js')\nimport('./loader');\nexport const name = \"hello\";\n`;\nconst result = transpiler.scanImports(code);\n`);\n`\n`json#Results\n[\n  {\n    kind: \"import-statement\",\n    path: \"react\"\n  }, {\n    kind: \"require-call\",\n    path: \"./cjs.js\"\n  }, {\n    kind: \"dynamic-import\",\n    path: \"./loader\"\n  }\n]\n`\n{% /codetabs %}\nReference\n`ts\ntype Loader = \"jsx\" | \"js\" | \"ts\" | \"tsx\";\ninterface TranspilerOptions {\n  // Replace key with value. Value must be a JSON string.\n  // { \"process.env.NODE_ENV\": \"\\\"production\\\"\" }\n  define?: Record<string, string>,\n  // Default loader for this transpiler\n  loader?: Loader,\n  // Default platform to target\n  // This affects how import and/or require is used\n  target?: \"browser\" | \"bun\" | \"node\",\n  // Specify a tsconfig.json file as stringified JSON or an object\n  // Use this to set a custom JSX factory, fragment, or import source\n  // For example, if you want to use Preact instead of React. Or if you want to use Emotion.\n  tsconfig?: string | TSConfig,\n  // Replace imports with macros\n  macro?: MacroMap,\n  // Specify a set of exports to eliminate\n  // Or rename certain exports\n  exports?: {\n      eliminate?: string[];\n      replace?: Record<string, string>;\n  },\n  // Whether to remove unused imports from transpiled file\n  // Default: false\n  trimUnusedImports?: boolean,\n  // Whether to enable a set of JSX optimizations\n  // jsxOptimizationInline ...,\n  // Experimental whitespace minification\n  minifyWhitespace?: boolean,\n  // Whether to inline constant values\n  // Typically improves performance and decreases bundle size\n  // Default: true\n  inline?: boolean,\n}\n// Map import paths to macros\ninterface MacroMap {\n  // {\n  //   \"react-relay\": {\n  //     \"graphql\": \"bun-macro-relay/bun-macro-relay.tsx\"\n  //   }\n  // }\n  [packagePath: string]: {\n    [importItemName: string]: string,\n  },\n}\nclass Bun.Transpiler {\n  constructor(options: TranspilerOptions)\n  transform(code: string, loader?: Loader): Promise<string>\n  transformSync(code: string, loader?: Loader): string\n  scan(code: string): {exports: string[], imports: Import}\n  scanImports(code: string): Import[]\n}\ntype Import = {\n  path: string,\n  kind:\n  // import foo from 'bar'; in JavaScript\n  | \"import-statement\"\n  // require(\"foo\") in JavaScript\n  | \"require-call\"\n  // require.resolve(\"foo\") in JavaScript\n  | \"require-resolve\"\n  // Dynamic import() in JavaScript\n  | \"dynamic-import\"\n  // @import() in CSS\n  | \"import-rule\"\n  // url() in CSS\n  | \"url-token\"\n  // The import was injected by Bun\n  | \"internal\"\u00a0\n  // Entry point (not common)\n  | \"entry-point\"\n}\nconst transpiler = new Bun.Transpiler({ loader: \"jsx\" });\n`"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/utils.md"}, {"role": "assistant", "content": "A  containing the version of the  CLI that is currently running.\n`ts\nBun.version;\n// => \"0.6.4\"\n`\nThe git commit of Bun that was compiled to create the current  CLI.\n`ts\nBun.revision;\n// => \"f02561530fda1ee9396f51c8bc99b38716e38296\"\n`\nAn alias for .\nAn absolute path to the entrypoint of the current program (the file that was executed with ).\n`ts#script.ts\nBun.main;\n// /path/to/script.ts\n`\nThis is particular useful for determining whether a script is being directly executed, as opposed to being imported by another script.\n`ts\nif (import.meta.path === Bun.main) {\n  // this script is being directly executed\n} else {\n  // this file is being imported from another script\n}\n`\nThis is analogous to the  trick in Node.js.\n (added in Bun v0.5.6)\nReturns a  that resolves after the given number of milliseconds.\n`ts\nconsole.log(\"hello\");\nawait Bun.sleep(1000);\nconsole.log(\"hello one second later!\");\n`\nAlternatively, pass a  object to receive a  that resolves at that point in time.\n`ts\nconst oneSecondInFuture = new Date(Date.now() + 1000);\nconsole.log(\"hello\");\nawait Bun.sleep(oneSecondInFuture);\nconsole.log(\"hello one second later!\");\n`\n (added in Bun v0.5.6)\nA blocking synchronous version of .\n`ts\nconsole.log(\"hello\");\nBun.sleepSync(1000); // blocks thread for one second\nconsole.log(\"hello one second later!\");\n`\nReturns the path to an executable, similar to typing  in your terminal.\n`ts\nconst ls = Bun.which(\"ls\");\nconsole.log(ls); // \"/usr/bin/ls\"\n`\nBy default Bun looks at the current  environment variable to determine the path. To configure :\n`ts\nconst ls = Bun.which(\"ls\", {\n  PATH: \"/usr/local/bin:/usr/bin:/bin\",\n});\nconsole.log(ls); // \"/usr/bin/ls\"\n`\nPass a  option to resolve for executable from within a specific directory.\n`ts\nconst ls = Bun.which(\"ls\", {\n  cwd: \"/tmp\",\n  PATH: \"\",\n});\nconsole.log(ls); // null\n`\n (added in Bun v0.2.2)\nReads a promise's result without  or , but only if the promise has already fulfilled or rejected.\n`ts\nimport { peek } from \"bun\";\nconst promise = Promise.resolve(\"hi\");\n// no await!\nconst result = peek(promise);\nconsole.log(result); // \"hi\"\n`\nThis is important when attempting to reduce number of extraneous microticks in performance-sensitive code. It's an advanced API and you probably shouldn't use it unless you know what you're doing.\n`ts\nimport { peek } from \"bun\";\nimport { expect, test } from \"bun:test\";\ntest(\"peek\", () => {\n  const promise = Promise.resolve(true);\n  // no await necessary!\n  expect(peek(promise)).toBe(true);\n  // if we peek again, it returns the same value\n  const again = peek(promise);\n  expect(again).toBe(true);\n  // if we peek a non-promise, it returns the value\n  const value = peek(42);\n  expect(value).toBe(42);\n  // if we peek a pending promise, it returns the promise again\n  const pending = new Promise(() => {});\n  expect(peek(pending)).toBe(pending);\n  // If we peek a rejected promise, it:\n  // - returns the error\n  // - does not mark the promise as handled\n  const rejected = Promise.reject(\n    new Error(\"Successfully tested promise rejection\"),\n  );\n  expect(peek(rejected).message).toBe(\"Successfully tested promise rejection\");\n});\n`\nThe  function lets you read the status of a promise without resolving it.\n`ts\nimport { peek } from \"bun\";\nimport { expect, test } from \"bun:test\";\ntest(\"peek.status\", () => {\n  const promise = Promise.resolve(true);\n  expect(peek.status(promise)).toBe(\"fulfilled\");\n  const pending = new Promise(() => {});\n  expect(peek.status(pending)).toBe(\"pending\");\n  const rejected = Promise.reject(new Error(\"oh nooo\"));\n  expect(peek.status(rejected)).toBe(\"rejected\");\n});\n`\nOpens a file in your default editor. Bun auto-detects your editor via the  or  environment variables.\n`ts\nconst currentFile = import.meta.url;\nBun.openInEditor(currentFile);\n`\nYou can override this via the  setting in your \n`toml-diff#bunfig.toml\n+ [debug]\n+ editor = \"code\"\n`\nOr specify an editor with the  param. You can also specify a line and column number.\n`ts\nBun.openInEditor(import.meta.url, {\n  editor: \"vscode\", // or \"subl\"\n  line: 10,\n  column: 5,\n});\n`\nBun.ArrayBufferSink;\nNestedly checks if two objects are equivalent. This is used internally by  in .\n`ts\nconst foo = { a: 1, b: 2, c: { d: 3 } };\n// true\nBun.deepEquals(foo, { a: 1, b: 2, c: { d: 3 } });\n// false\nBun.deepEquals(foo, { a: 1, b: 2, c: { d: 4 } });\n`\nA third boolean parameter can be used to enable \"strict\" mode. This is used by  in the test runner.\n`ts\nconst a = { entries: [1, 2] };\nconst b = { entries: [1, 2], extra: undefined };\nBun.deepEquals(a, b); // => true\nBun.deepEquals(a, b, true); // => false\n`\nIn strict mode, the following are considered unequal:\n`ts\n// undefined values\nBun.deepEquals({}, { a: undefined }, true); // false\n// undefined in arrays\nBun.deepEquals([\"asdf\"], [\"asdf\", undefined], true); // false\n// sparse arrays\nBun.deepEquals([, 1], [undefined, 1], true); // false\n// object literals vs instances w/ same properties\nclass Foo {\n  a = 1;\n}\nBun.deepEquals(new Foo(), { a: 1 }, true); // false\n`\nEscapes the following characters from an input string:\n becomes \n becomes \n becomes \n becomes \n becomes \nThis function is optimized for large input. On an M1X, it processes 480 MB/s -\n20 GB/s, depending on how much data is being escaped and whether there is non-ascii\ntext. Non-string types will be converted to a string before escaping.\n<!--  -->\nConverts a  URL to an absolute path.\n`ts\nconst path = Bun.fileURLToPath(new URL(\"file:///foo/bar.txt\"));\nconsole.log(path); // \"/foo/bar.txt\"\n`\nConverts an absolute path to a  URL.\n`ts\nconst url = Bun.pathToFileURL(\"/foo/bar.txt\");\nconsole.log(url); // \"file:///foo/bar.txt\"\n`\n<!-- Bun.hash; -->\nCompresses a  using zlib's GZIP algorithm.\n`ts\nconst buf = Buffer.from(\"hello\".repeat(100)); // Buffer extends Uint8Array\nconst compressed = Bun.gzipSync(buf);\nbuf; // => Uint8Array(500)\ncompressed; // => Uint8Array(30)\n`\nOptionally, pass a parameters object as the second argument:\n{% details summary=\"zlib compression options\"%}\n`ts\nexport type ZlibCompressionOptions = {\n  /\n    The compression level to use. Must be between  and .\n    - A value of  uses the default compression level (Currently )\n    - A value of  gives no compression\n    - A value of  gives least compression, fastest speed\n    - A value of  gives best compression, slowest speed\n   /\n  level?: -1 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9;\n  /\n    How much memory should be allocated for the internal compression state.\n   \n    A value of  uses minimum memory but is slow and reduces compression ratio.\n   \n    A value of  uses maximum memory for optimal speed. The default is .\n   /\n  memLevel?: 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9;\n  /\n    The base 2 logarithm of the window size (the size of the history buffer).\n   \n    Larger values of this parameter result in better compression at the expense of memory usage.\n   \n    The following value ranges are supported:\n    - : The output will have a zlib header and footer (Deflate)\n    - : The output will not have a zlib header or footer (Raw Deflate)\n    -  (16+): The output will have a gzip header and footer (gzip)\n   \n    The gzip header will have no file name, no extra data, no comment, no modification time (set to zero) and no header CRC.\n   /\n  windowBits?:\n    | -9\n    | -10\n    | -11\n    | -12\n    | -13\n    | -14\n    | -15\n    | 9\n    | 10\n    | 11\n    | 12\n    | 13\n    | 14\n    | 15\n    | 25\n    | 26\n    | 27\n    | 28\n    | 29\n    | 30\n    | 31;\n  /\n    Tunes the compression algorithm.\n   \n    - : For normal data (Default)\n    - : For data produced by a filter or predictor\n    - : Force Huffman encoding only (no string match)\n    - : Limit match distances to one (run-length encoding)\n    -  prevents the use of dynamic Huffman codes\n   \n     is designed to be almost as fast as , but give better compression for PNG image data.\n   \n     forces more Huffman coding and less string matching, it is\n    somewhat intermediate between  and .\n    Filtered data consists mostly of small values with a somewhat random distribution.\n   /\n  strategy?: number;\n};\n`\n{% /details %}\nDecompresses a  using zlib's GUNZIP algorithm.\n`ts\nconst buf = Buffer.from(\"hello\".repeat(100)); // Buffer extends Uint8Array\nconst compressed = Bun.gunzipSync(buf);\nconst dec = new TextDecoder();\nconst uncompressed = Bun.inflateSync(compressed);\ndec.decode(uncompressed);\n// => \"hellohellohello...\"\n`\nCompresses a  using zlib's DEFLATE algorithm.\n`ts\nconst buf = Buffer.from(\"hello\".repeat(100));\nconst compressed = Bun.deflateSync(buf);\nbuf; // => Uint8Array(25)\ncompressed; // => Uint8Array(10)\n`\nThe second argument supports the same set of configuration options as .\nDecompresses a  using zlib's INFLATE algorithm.\n`ts\nconst buf = Buffer.from(\"hello\".repeat(100));\nconst compressed = Bun.deflateSync(buf);\nconst dec = new TextDecoder();\nconst decompressed = Bun.inflateSync(compressed);\ndec.decode(decompressed);\n// => \"hellohellohello...\"\n`\nSerializes an object to a  exactly as it would be printed by .\n`ts\nconst obj = { foo: \"bar\" };\nconst str = Bun.inspect(obj);\n// => '{\\nfoo: \"bar\" \\n}'\nconst arr = new Uint8Array([1, 2, 3]);\nconst str = Bun.inspect(arr);\n// => \"Uint8Array(3) [ 1, 2, 3 ]\"\n`\nThis is the symbol that Bun uses to implement . You can override this to customize how your objects are printed. It is identical to  in Node.js.\n`ts\nclass Foo {\n  Bun.inspect.custom {\n    return \"foo\";\n  }\n}\nconst foo = new Foo();\nconsole.log(foo); // => \"foo\"\n`\nReturns the number of nanoseconds since the current  process started, as a . Useful for high-precision timing and benchmarking.\n`ts\nBun.nanoseconds();\n// => 7288958\n`\nBun implements a set of convenience functions for asynchronously consuming the body of a  and converting it to various binary formats.\n`ts\nconst stream = (await fetch(\"https://bun.sh\")).body;\nstream; // => ReadableStream\nawait Bun.readableStreamToArrayBuffer(stream);\n// => ArrayBuffer\nawait Bun.readableStreamToBlob(stream);\n// => Blob\nawait Bun.readableStreamToJSON(stream);\n// => object\nawait Bun.readableStreamToText(stream);\n// => string\n// returns all chunks as an array\nawait Bun.readableStreamToArray(stream);\n// => unknown[]\n// returns all chunks as a FormData object (encoded as x-www-form-urlencoded)\nawait Bun.readableStreamToFormData(stream);\n// returns all chunks as a FormData object (encoded as multipart/form-data)\nawait Bun.readableStreamToFormData(stream, multipartFormBoundary);\n`\nResolves a file path or module specifier using Bun's internal module resolution algorithm. The first argument is the path to resolve, and the second argument is the \"root\". If no match is found, an  is thrown.\n`ts\nBun.resolveSync(\"./foo.ts\", \"/path/to/project\");\n// => \"/path/to/project/foo.ts\"\nBun.resolveSync(\"zod\", \"/path/to/project\");\n// => \"/path/to/project/node_modules/zod/index.ts\"\n`\nTo resolve relative to the current working directory, pass  or  as the root.\n`ts\nBun.resolveSync(\"./foo.ts\", process.cwd());\nBun.resolveSync(\"./foo.ts\", \"/path/to/project\");\n`\nTo resolve relative to the directory containing the current file, pass .\n`ts\nBun.resolveSync(\"./foo.ts\", import.meta.dir);\n`\n &  in \nTo save a JavaScript value into an ArrayBuffer & back, use  and  from the  module.\n`js\nimport { serialize, deserialize } from \"bun:jsc\";\nconst buf = serialize({ foo: \"bar\" });\nconst obj = deserialize(buf);\nconsole.log(obj); // => { foo: \"bar\" }\n`\nInternally,  and  serialize and deserialize the same way. This exposes the underlying HTML Structured Clone Algorithm to JavaScript as an ArrayBuffer."}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/websockets.md"}, {"role": "assistant", "content": "supports server-side WebSockets, with on-the-fly compression, TLS support, and a Bun-native publish-subscribe API.\n{% callout %}\n\u26a1\ufe0f 7x more throughput \u2014 Bun's WebSockets are fast. For a simple chatroom on Linux x64, Bun can handle 7x more requests per second than Node.js + .\n| Messages sent per second | Runtime                        | Clients |\n| ------------------------ | ------------------------------ | ------- |\n| ~700,000                 | () Bun v0.2.1 (x64) | 16      |\n| ~100,000                 | () Node v18.10.0 (x64)     | 16      |\nInternally Bun's WebSocket implementation is built on uWebSockets.\n{% /callout %}\nStart a WebSocket server\nBelow is a simple WebSocket server built with , in which all incoming requests are upgraded to WebSocket connections in the  handler. The socket handlers are declared in the  parameter.\n`ts\nBun.serve({\n  fetch(req, server) {\n    // upgrade the request to a WebSocket\n    if (server.upgrade(req)) {\n      return; // do not return a Response\n    }\n    return new Response(\"Upgrade failed :(\", { status: 500 });\n  },\n  websocket: {}, // handlers\n});\n`\nThe following WebSocket event handlers are supported:\n`ts\nBun.serve({\n  fetch(req, server) {}, // upgrade logic\n  websocket: {\n    message(ws, message) {}, // a message is received\n    open(ws) {}, // a socket is opened\n    close(ws, code, message) {}, // a socket is closed\n    drain(ws) {}, // the socket is ready to receive more data\n  },\n});\n`\n{% details summary=\"An API designed for speed\" %}\nIn Bun, handlers are declared once per server, instead of per socket.\n expects you to pass a  object to the  method which has methods for , , , , and . This is different than the client-side  class which extends  (onmessage, onopen, onclose),\nClients tend to not have many socket connections open so an event-based API makes sense.\nBut servers tend to have many socket connections open, which means:\nTime spent adding/removing event listeners for each connection adds up\nExtra memory spent on storing references to callbacks function for each connection\nUsually, people create new functions for each connection, which also means more memory\nSo, instead of using an event-based API,  expects you to pass a single object with methods for each event in  and it is reused for each connection.\nThis leads to less memory usage and less time spent adding/removing event listeners.\n{% /details %}\nThe first argument to each handler is the instance of  handling the event. The  class is a fast, Bun-native implementation of  with some additional features.\n`ts\nBun.serve({\n  fetch(req, server) {}, // upgrade logic\n  websocket: {\n    message(ws, message) {\n      ws.send(message); // echo back the message\n    },\n  },\n});\n`\nSending messages\nEach  instance has a  method for sending messages to the client. It supports a range of input types.\n`ts\nws.send(\"Hello world\"); // string\nws.send(response.arrayBuffer()); // ArrayBuffer\nws.send(new Uint8Array([1, 2, 3])); // TypedArray | DataView\n`\nHeaders\nOnce the upgrade succeeds, Bun will send a  response per the spec. Additional  can be attched to this  in the call to .\n`ts\nBun.serve({\n  fetch(req, server) {\n    const sessionId = await generateSessionId();\n    server.upgrade(req, {\n      headers: {\n        \"Set-Cookie\": ,\n      },\n    });\n  },\n  websocket: {}, // handlers\n});\n`\nContextual data\nContextual  can be attached to a new WebSocket in the  call. This data is made available on the  property inside the WebSocket handlers.\n`ts\ntype WebSocketData = {\n  createdAt: number;\n  channelId: string;\n  authToken: string;\n};\n// TypeScript: specify the type of \nBun.serve<WebSocketData>({\n  fetch(req, server) {\n    // use a library to parse cookies\n    const cookies = parseCookies(req.headers.get(\"Cookie\"));\n    server.upgrade(req, {\n      // this object must conform to WebSocketData\n      data: {\n        createdAt: Date.now(),\n        channelId: new URL(req.url).searchParams.get(\"channelId\"),\n        authToken: cookies[\"X-Token\"],\n      },\n    });\n    return undefined;\n  },\n  websocket: {\n    // handler called when a message is received\n    async message(ws, message) {\n      const user = getUserFromToken(ws.data.authToken);\n      await saveMessageToDatabase({\n        channel: ws.data.channelId,\n        message: String(message),\n        userId: user.id,\n      });\n    },\n  },\n});\n`\nTo connect to this server from the browser, create a new .\n`ts#browser.js\nconst socket = new WebSocket(\"ws://localhost:3000/chat\");\nsocket.addEventListener(\"message\", event => {\n  console.log(event.data);\n})\n`\n{% callout %}\nIdentifying users \u2014\u00a0The cookies that are currently set on the page will be sent with the WebSocket upgrade request and available on  in the  handler. Parse these cookies to determine the identity of the connecting user and set the value of  accordingly.\n{% /callout %}\nPub/Sub\nBun's  implementation implements a native publish-subscribe API for topic-based broadcasting. Individual sockets can  to a topic (specified with a string identifier) and  messages to all other subscribers to that topic. This topic-based broadcast API is similar to MQTT and Redis Pub/Sub.\n`ts\nconst server = Bun.serve<{ username: string }>({\n  fetch(req, server) {\n    const url = new URL(req.url);\n    if (url.pathname === \"/chat\") {\n      console.log();\n      const username = getUsernameFromReq(req);\n      const success = server.upgrade(req, { data: { username } });\n      return success\n        ? undefined\n        : new Response(\"WebSocket upgrade error\", { status: 400 });\n    }\n    return new Response(\"Hello world\");\n  },\n  websocket: {\n    open(ws) {\n      const msg = ;\n      ws.subscribe(\"the-group-chat\");\n      ws.publish(\"the-group-chat\", msg);\n    },\n    message(ws, message) {\n      // this is a group chat\n      // so the server re-broadcasts incoming message to everyone\n      ws.publish(\"the-group-chat\", );\n    },\n    close(ws) {\n      const msg = ;\n      ws.unsubscribe(\"the-group-chat\");\n      ws.publish(\"the-group-chat\", msg);\n    },\n  },\n});\nconsole.log();\n`\nCalling  will send the message to all subscribers of a topic _except_ the socket that called .\nCompression\nPer-message compression can be enabled with the  parameter.\n`ts\nBun.serve({\n  fetch(req, server) {}, // upgrade logic\n  websocket: {\n    // enable compression and decompression\n    perMessageDeflate: true,\n  },\n});\n`\nCompression can be enabled for individual messages by passing a  as the second argument to .\n`ts\nws.send(\"Hello world\", true);\n`\nFor fine-grained control over compression characteristics, refer to the Reference.\nBackpressure\nThe  method of  returns a  indicating the result of the operation.\n \u2014 The message was enqueued but there is backpressure\n \u2014 The message was dropped due to a connection issue\n \u2014 The number of bytes sent\nThis gives you better control over backpressure in your server.\nConnect to a  server\nTo connect to an external socket server, either from a browser or from Bun, create an instance of  with the constructor.\n`ts\nconst socket = new WebSocket(\"ws://localhost:3000\");\n`\nIn browsers, the cookies that are currently set on the page will be sent with the WebSocket upgrade request. This is a standard feature of the  API.\nFor convenience, Bun lets you setting custom headers directly in the constructor. This is a Bun-specific extension of the  standard. _This will not work in browsers._\n`ts\nconst socket = new WebSocket(\"ws://localhost:3000\", {\n  headers: {\n    // custom headers\n  },\n});\n`\nTo add event listeners to the socket:\n`ts\n// message is received\nsocket.addEventListener(\"message\", event => {});\n// socket opened\nsocket.addEventListener(\"open\", event => {});\n// socket closed\nsocket.addEventListener(\"close\", event => {});\n// error handler\nsocket.addEventListener(\"error\", event => {});\n`\nReference\n`ts\nnamespace Bun {\n  export function serve(params: {\n    fetch: (req: Request, server: Server) => Response | Promise<Response>;\n    websocket?: {\n      message: (\n        ws: ServerWebSocket,\n        message: string | ArrayBuffer | Uint8Array,\n      ) => void;\n      open?: (ws: ServerWebSocket) => void;\n      close?: (ws: ServerWebSocket) => void;\n      error?: (ws: ServerWebSocket, error: Error) => void;\n      drain?: (ws: ServerWebSocket) => void;\n      perMessageDeflate?:\n        | boolean\n        | {\n            compress?: boolean | Compressor;\n            decompress?: boolean | Compressor;\n          };\n    };\n  }): Server;\n}\ntype Compressor =\n  | \n  | \n  | \n  | \n  | \n  | \n  | \n  | \n  | \n  | \n  | ;\ninterface Server {\n  pendingWebsockets: number;\n  publish(\n    topic: string,\n    data: string | ArrayBufferView | ArrayBuffer,\n    compress?: boolean,\n  ): number;\n  upgrade(\n    req: Request,\n    options?: {\n      headers?: HeadersInit;\n      data?: any;\n    },\n  ): boolean;\n}\ninterface ServerWebSocket {\n  readonly data: any;\n  readonly readyState: number;\n  readonly remoteAddress: string;\n  send(message: string | ArrayBuffer | Uint8Array, compress?: boolean): number;\n  close(code?: number, reason?: string): void;\n  subscribe(topic: string): void;\n  unsubscribe(topic: string): void;\n  publish(topic: string, message: string | ArrayBuffer | Uint8Array): void;\n  isSubscribed(topic: string): boolean;\n  cork(cb: (ws: ServerWebSocket) => void): void;\n}\n`\n<!--\n{% param name=\"params\" %}\nConfiguration object for WebSocket server\n{% /param %}\n{% param name=\" fetch\" %}\nCall  to upgrade the request to a WebSocket connection. This method returns  if the upgrade succeeds, or  if the upgrade fails.\n{% /param %}\n{% param name=\" websocket\" %}\nConfiguration object for WebSocket server\n{% /param %}\n{% param name=\"  message\" %}\nThis handler is called when a  receives a message.\n{% /param %}\n{% param name=\"  open\" %}\nThis handler is called when a  is opened.\n{% /param %}\n{% param name=\"  close\" %}\nThis handler is called when a  is closed.\n{% /param %}\n{% param name=\"  drain\" %}\nThis handler is called when a  is ready to receive more data.\n{% /param %}\n{% param name=\"  perMessageDeflate\" %}\nEnable per-message compression and decompression. This is a boolean value or an object with  and  properties. Each property can be a boolean value or one of the following  types:\n{% /param %}\n{% param name=\"readyState\" %}\nThe current state of the  connection. This is one of the following values:\n \n \n \n \n{% /param %}\n{% param name=\"remoteAddress\" %}\nThe remote address of the  connection\n{% /param %}\n{% param name=\"data\" %}\nThe data associated with the  connection. This is set in the  call.\n{% /param %}\n{% param name=\".send()\" %}\nSend a message to the client. Returns a  indicating the result of the operation.\n: the message was enqueued but there is backpressure\n: the message was dropped due to a connection issue\n: the number of bytes sent\nThe  argument will enable compression for this message, even if the  option is disabled.\n{% /param %}\n{% param name=\".subscribe()\" %}\nSubscribe to a topic\n{% /param %}\n{% param name=\".unsubscribe()\" %}\nUnsubscribe from a topic\n{% /param %}\n{% param name=\".publish()\" %}\nSend a message to all subscribers of a topic\n{% /param %}\n{% param name=\".isSubscribed()\" %}\nCheck if the  is subscribed to a topic\n{% /param %}\n{% param name=\".cork()\" %}\nBatch a set of operations on a  connection. The , , and  callbacks are automatically corked, so\nyou only need to call this if you are sending messages outside of those\ncallbacks or in async functions.\n`ts\nws.cork((ws) => {\n  ws.send(\"first\");\n  ws.send(\"second\");\n  ws.send(\"third\");\n});\n`\n{% /param %}\n{% param name=\".close()\" %}\nClose the  connection\n{% /param %}\n{% param name=\"pendingWebsockets\" %}\nNumber of in-flight  messages\n{% /param %}\n{% param name=\".publish()\" %}\nSend a message to all subscribers of a topic\n{% /param %}\n{% param name=\".upgrade()\" %}\nUpgrade a request to a  connection. Returns  if the upgrade succeeds, or  if the upgrade fails.\n{% /param %} -->"}]}
{"messages": [{"role": "user", "content": "Provide the content of docs/api/workers.md"}, {"role": "assistant", "content": "{% callout %}\n support was added in Bun v0.7.0.\n{% /callout %}\n lets you start and communicate with a new JavaScript instance running on a separate thread while sharing I/O resources with the main thread.\nBun implements a minimal version of the Web Workers API with extensions that make it work better for server-side use cases. Like the rest of Bun,  in Bun support CommonJS, ES Modules, TypeScript, JSX, TSX and more out of the box. No extra build steps are necessary.\nCreating a \nLike in browsers,  is a global. Use it to create a new worker thread.\nFrom the main thread:\n`js#Main_thread\nconst workerURL = new URL(\"worker.ts\", import.meta.url).href;\nconst worker = new Worker(workerURL);\nworker.postMessage(\"hello\");\nworker.onmessage = event => {\n  console.log(event.data);\n};\n`\nWorker thread:\n`ts#worker.ts_(Worker_thread)\nself.onmessage = (event: MessageEvent) => {\n  console.log(event.data);\n  postMessage(\"world\");\n};\n`\nYou can use / syntax in your worker code. Unlike in browsers, there's no need to specify  to use ES Modules.\nTo simplify error handling, the initial script to load is resolved at the time  is called.\n`js\nconst worker = new Worker(\"/not-found.js\");\n// throws an error immediately\n`\nThe specifier passed to  is resolved relative to the project root (like typing ).\nThe  event is emitted when a worker is created and ready to receive messages. This can be used to send an initial message to a worker once it's ready. (This event does not exist in browsers.)\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href);\nworker.addEventListener(\"open\", () => {\n  console.log(\"worker is ready\");\n});\n`\nMessages are automatically enqueued until the worker is ready, so there is no need to wait for the  event to send messages.\nMessages with \nTo send messages, use  and . This leverages the HTML Structured Clone Algorithm.\n`js\n// On the worker thread,  is automatically \"routed\" to the parent thread.\npostMessage({ hello: \"world\" });\n// On the main thread\nworker.postMessage({ hello: \"world\" });\n`\nTo receive messages, use the  event handler on the worker and main thread.\n`js\n// Worker thread:\nself.addEventListener(\"message\", event => {\n  console.log(event.data);\n});\n// or use the setter:\n// self.onmessage = fn\n// if on the main thread\nworker.addEventListener(\"message\", event => {\n  console.log(event.data);\n});\n// or use the setter:\n// worker.onmessage = fn\n`\nTerminating a worker\nA  instance terminates automatically once it's event loop has no work left to do. Attaching a  listener on the global or any s will keep the event loop alive. To forcefully terminate a , call .\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href);\n// ...some time later\nworker.terminate();\n`\nThis will cause the worker's to exit as soon as possible.\nA worker can terminate itself with . This does not terminate the main process. Like in Node.js,  and  are emitted on the worker thread (and not on the main thread), and the exit code is passed to the  event.\nThe  event is emitted when a worker has been terminated. It can take some time for the worker to actually terminate, so this event is emitted when the worker has been marked as terminated. The  will contain the exit code passed to , or 0 if closed for other reasons.\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href);\nworker.addEventListener(\"close\", event => {\n  console.log(\"worker is being closed\");\n});\n`\nThis event does not exist in browsers.\nManaging lifetime\nBy default, an active  will keep the main (spawning) process alive, so async tasks like  and promises will keep the process alive. Attaching  listeners will also keep the  alive.\nTo stop a running worker from keeping the process alive, call . This decouples the lifetime of the worker to the lifetime of the main process, and is equivlent to what Node.js'  does.\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href);\nworker.unref();\n`\nNote:  is not available in browers.\nTo keep the process alive until the  terminates, call . A ref'd worker is the default behavior, and still needs something going on in the event loop (such as a  listener) for the worker to continue running.\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href);\nworker.unref();\n// later...\nworker.ref();\n`\nAlternatively, you can also pass an  object to :\n`ts\nconst worker = new Worker(new URL(\"worker.ts\", import.meta.url).href, {\n  ref: false,\n});\n`\nNote:  is not available in browers.\nMemory usage with \nJavaScript instances can use a lot of memory. Bun's  supports a  mode that reduces memory usage, at a cost of performance. To enable  mode, pass  to the  object in the  constructor.\n`js\nconst worker = new Worker(\"./i-am-smol.ts\", {\n  smol: true,\n});\n`\n{% details summary=\"What does  mode actually do?\" %}\nSetting  sets  to be  instead of the default .\n{% /details %}"}]}